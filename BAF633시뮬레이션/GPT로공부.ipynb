{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc30777b",
   "metadata": {},
   "source": [
    "# 자체적으로 관련 내용 GPT 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6427e",
   "metadata": {},
   "source": [
    "## acceptance-rejection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cadd4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, uniform\n",
    "\n",
    "# Define the range for z\n",
    "z = np.linspace(-5, 5, 1000)\n",
    "\n",
    "# 1. Original Distribution f_X (Standard Normal)\n",
    "f_X = norm.pdf(z, loc=0, scale=1)  # Mean=0, Std Dev=1\n",
    "\n",
    "# 2. Majoring Function c * f_Z (Uniform Distribution)\n",
    "f_Z = uniform.pdf(z, loc=-5, scale=10)  # Uniform over [-5, 5]\n",
    "c = 4\n",
    "majoring_function = c * f_Z  # Constant value of 0.4\n",
    "\n",
    "# 3. Acceptance Rate f_X(z) / (c * f_Z(z))\n",
    "acceptance_rate = f_X / majoring_function  # Should be <= 1\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot f_X(z)\n",
    "plt.plot(z, f_X, label=r'Original Distribution $f_X(z)$ (Normal)', color='blue')\n",
    "\n",
    "# Plot c * f_Z(z)\n",
    "plt.plot(z, majoring_function, label=r'Majoring Function $c \\cdot f_Z(z)$ (Uniform)', color='red', linestyle='--')\n",
    "\n",
    "# Plot Acceptance Rate\n",
    "plt.plot(z, acceptance_rate, label=r'Acceptance Rate $\\frac{f_X(z)}{c \\cdot f_Z(z)}$', color='green')\n",
    "\n",
    "# Add horizontal line at acceptance rate = 1\n",
    "plt.axhline(y=1, color='gray', linestyle=':', linewidth=1)\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('Density / Acceptance Rate')\n",
    "plt.title('Acceptance-Rejection Method Visualization')\n",
    "\n",
    "# Legend\n",
    "plt.legend()\n",
    "\n",
    "# Grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Show Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729917b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, expon\n",
    "\n",
    "# Parameters\n",
    "lambda_param = 1  # Rate parameter for Exponential distribution\n",
    "c = 0.658         # Majoring constant calculated to satisfy c * f_Z(z) >= f_X(z) for all z >=0\n",
    "\n",
    "# Define the range for z (0 to 5 for Exponential)\n",
    "z = np.linspace(0, 5, 1000)\n",
    "\n",
    "# 1. Original Distribution f_X (Standard Normal)\n",
    "f_X = norm.pdf(z, loc=0, scale=1)  # Mean=0, Std Dev=1\n",
    "\n",
    "# 2. Proposal Distribution f_Z (Exponential)\n",
    "f_Z = expon.pdf(z, scale=1/lambda_param)  # Exponential with lambda=1\n",
    "\n",
    "# Majoring Function c * f_Z(z)\n",
    "majoring_function = c * f_Z  # 0.658 * e^{-z}\n",
    "\n",
    "# 3. Acceptance Rate f_X(z) / (c * f_Z(z))\n",
    "acceptance_rate = f_X / majoring_function  # Should be <=1\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot f_X(z)\n",
    "plt.plot(z, f_X, label=r'Original Distribution $f_X(z)$ (Normal)', color='blue')\n",
    "\n",
    "# Plot c * f_Z(z)\n",
    "plt.plot(z, majoring_function, label=r'Majoring Function $c \\cdot f_Z(z)$ (Exponential)', color='red', linestyle='--')\n",
    "\n",
    "# Plot Acceptance Rate\n",
    "plt.plot(z, acceptance_rate, label=r'Acceptance Rate $\\frac{f_X(z)}{c \\cdot f_Z(z)}$', color='green')\n",
    "\n",
    "# Add horizontal line at acceptance rate = 1\n",
    "plt.axhline(y=1, color='gray', linestyle=':', linewidth=1)\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('Density / Acceptance Rate')\n",
    "plt.title('Acceptance-Rejection Method Visualization with Exponential Proposal')\n",
    "\n",
    "# Legend\n",
    "plt.legend()\n",
    "\n",
    "# Grid for better readability\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Show Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afd912",
   "metadata": {},
   "source": [
    "Brownian Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25fea7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def ki_digital_bb(s0, maturity, ki_barrier, barrier, gain_coupon, loss_coupon, fulldummy, rfr, div, vol, nSim):\n",
    "    \"\"\"\n",
    "    Pricing a barrier option using the Brownian Bridge method to enhance efficiency.\n",
    "    \n",
    "    Parameters:\n",
    "    - s0: Initial asset price\n",
    "    - maturity: Time to maturity (in years)\n",
    "    - ki_barrier: Lower barrier (e.g., 0.7 * s0)\n",
    "    - barrier: Upper barrier (e.g., 0.8 * s0)\n",
    "    - gain_coupon: Payoff if S_T >= barrier\n",
    "    - loss_coupon: Payoff if S_T < barrier and min(S(t)) < ki_barrier\n",
    "    - fulldummy: Payoff if S_T < barrier and min(S(t)) >= ki_barrier\n",
    "    - rfr: Risk-free rate\n",
    "    - div: Dividend yield\n",
    "    - vol: Volatility of the asset\n",
    "    - nSim: Number of Monte Carlo simulations\n",
    "    \n",
    "    Returns:\n",
    "    - val: Estimated option price\n",
    "    - cal_time: Calculation time\n",
    "    - barrier_prob: Probability that terminal price >= barrier\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    days = 250  # Number of trading days in a year\n",
    "    ntime = int(days * maturity)  # Total number of time steps\n",
    "    time_grid = np.linspace(0, maturity, ntime + 1)  # Time grid from 0 to T\n",
    "    drift = rfr - div - 0.5 * vol ** 2  # Drift component of GBM\n",
    "    dt = time_grid[1] - time_grid[0]  # Time step size\n",
    "    \n",
    "    sum_payoff = 0  # Initialize sum of payoffs\n",
    "    barrier_prob_cnt = 0  # Count of simulations where S_T >= barrier\n",
    "    \n",
    "    # Step 1: Simulate all terminal asset prices at once\n",
    "    Z_terminal = np.random.normal(size=nSim)  # Generate all terminal Z's\n",
    "    s_mat = s0 * np.exp(drift * maturity + vol * np.sqrt(maturity) * Z_terminal)  # Terminal prices\n",
    "    \n",
    "    # Step 2: Iterate over each simulation\n",
    "    for i in range(nSim):\n",
    "        S_T = s_mat[i]  # Terminal price for simulation i\n",
    "        ratio_T = S_T / s0  # S_T / S0\n",
    "        \n",
    "        if ratio_T >= barrier:\n",
    "            # Case 1: Terminal price exceeds barrier\n",
    "            payoff = gain_coupon\n",
    "            barrier_prob_cnt += 1  # Increment barrier exceedance count\n",
    "        else:\n",
    "            # Case 2: Terminal price below barrier, need to check for lower barrier breach\n",
    "            \n",
    "            # Step 2a: Calculate standardized terminal log-price (Z_T)\n",
    "            Z_T = (np.log(S_T / s0) - drift * maturity) / vol\n",
    "            \n",
    "            # Step 2b: Simulate intermediate Brownian motion (W(t))\n",
    "            Z_intermediate = np.random.normal(size=ntime)  # Intermediate random variables\n",
    "            W_t = np.cumsum(Z_intermediate * np.sqrt(dt))  # Simulated Brownian motion path\n",
    "            \n",
    "            # Step 2c: Construct the Brownian Bridge\n",
    "            t_over_T = time_grid / maturity  # t / T\n",
    "            # Ensure W_t has the same length as time_grid by padding with zero at the start\n",
    "            W_t_full = np.zeros(ntime + 1)\n",
    "            W_t_full[1:] = W_t  # Shift W_t by one to align with time_grid\n",
    "            B_t = Z_T * t_over_T + W_t_full - t_over_T * W_t_full[-1]\n",
    "            \n",
    "            # Step 2d: Generate the asset price path using the bridge\n",
    "            S_t = s0 * np.exp(drift * time_grid + vol * B_t)\n",
    "            \n",
    "            # Step 2e: Determine the payoff based on barrier conditions\n",
    "            min_S_t = np.min(S_t)  # Minimum asset price during the path\n",
    "            ratio_min = min_S_t / s0  # min(S(t)) / S0\n",
    "            \n",
    "            if ratio_min >= ki_barrier:\n",
    "                # No breach of lower barrier\n",
    "                payoff = fulldummy\n",
    "            else:\n",
    "                # Breach of lower barrier\n",
    "                payoff = loss_coupon\n",
    "        \n",
    "        # Accumulate the payoff\n",
    "        sum_payoff += payoff\n",
    "    \n",
    "    # Step 3: Calculate the discounted average payoff\n",
    "    avg_payoff = sum_payoff / nSim\n",
    "    val = round(avg_payoff * np.exp(-rfr * maturity), 3)  # Discounted to present value\n",
    "    \n",
    "    # Step 4: Calculate calculation time and barrier exceedance probability\n",
    "    cal_time = round(time.time() - start_time, 3)\n",
    "    barrier_prob = round(barrier_prob_cnt / nSim, 3)\n",
    "    \n",
    "    return val, cal_time, barrier_prob\n",
    "\n",
    "# Example Usage:\n",
    "if __name__ == '__main__':\n",
    "    # Define parameters\n",
    "    s0 = 1\n",
    "    maturity = 1\n",
    "    ki_barrier = 0.7\n",
    "    barrier = 0.8\n",
    "    gain_coupon = 0.10\n",
    "    loss_coupon = -0.10\n",
    "    fulldummy = 0.10\n",
    "    rfr = 0.02\n",
    "    div = 0\n",
    "    vol = 0.3\n",
    "    nSim = 10000\n",
    "    \n",
    "    # Run simulations\n",
    "    val, cal_time, barrier_prob = ki_digital_bb(\n",
    "        s0, maturity, ki_barrier, barrier,\n",
    "        gain_coupon, loss_coupon, fulldummy,\n",
    "        rfr, div, vol, nSim\n",
    "    )\n",
    "    \n",
    "    print('Option Value (BB): {}, Elapsed Time: {} sec, Barrier Exceedance Probability: {}'.format(val, cal_time, barrier_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d395f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def visualize_brownian_bridge_simulation(s0, maturity, ki_barrier, barrier, drift, vol, dt):\n",
    "    \"\"\"\n",
    "    Simulates a single barrier option path using the Brownian Bridge method and visualizes each step.\n",
    "    \"\"\"\n",
    "    # Initialize time grid\n",
    "    days = int(250 * maturity)\n",
    "    ntime = days\n",
    "    time_grid = np.linspace(0, maturity, ntime + 1)\n",
    "    \n",
    "    # Step 1: Simulate Terminal Asset Price\n",
    "    Z_terminal = np.random.normal()\n",
    "    S_T = s0 * np.exp(drift * maturity + vol * np.sqrt(maturity) * Z_terminal)\n",
    "    ratio_T = S_T / s0\n",
    "    print(f\"Z_terminal: {Z_terminal:.4f}\")\n",
    "    print(f\"Terminal Asset Price (S_T): {S_T:.4f}\")\n",
    "    print(f\"Ratio_T: {ratio_T:.4f}\")\n",
    "    \n",
    "    if ratio_T >= barrier:\n",
    "        payoff = 0.10  # gain_coupon\n",
    "        print(f\"S_T >= Barrier ({barrier}) --> Payoff: {payoff}\")\n",
    "        \n",
    "        # Plotting the simple path\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot([0, maturity], [s0, S_T], marker='o', label='Asset Price Path (S(t))', color='blue')\n",
    "        plt.axhline(y=barrier, color='green', linestyle='--', label='Barrier (80%)')\n",
    "        plt.axhline(y=ki_barrier, color='red', linestyle='--', label='Lower Barrier (70%)')\n",
    "        plt.scatter([0, maturity], [s0, S_T], color='black', zorder=5, label='Start and End Points')\n",
    "        plt.title('Asset Price Path Above Barrier')\n",
    "        plt.xlabel('Time (Years)')\n",
    "        plt.ylabel('Asset Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"S_T < Barrier ({barrier}) --> Proceeding to Brownian Bridge\")\n",
    "        \n",
    "        # Step 2a: Calculate Z_T\n",
    "        Z_T = (np.log(S_T / s0) - drift * maturity) / vol\n",
    "        print(f\"Z_T: {Z_T:.4f}\")\n",
    "        \n",
    "        # Step 2b: Simulate Intermediate Brownian Motion W(t)\n",
    "        Z_intermediate = np.random.normal(size=ntime)\n",
    "        W_t = np.cumsum(Z_intermediate * np.sqrt(dt))\n",
    "        \n",
    "        # Step 2c: Construct the Brownian Bridge B(t)\n",
    "        t_over_T = time_grid / maturity\n",
    "        W_t_full = np.zeros(ntime + 1)\n",
    "        W_t_full[1:] = W_t  # Shift W_t to align with time_grid\n",
    "        B_t = Z_T * t_over_T + W_t_full - t_over_T * W_t_full[-1]\n",
    "        \n",
    "        # Step 2d: Generate Asset Price Path S(t)\n",
    "        S_t = s0 * np.exp(drift * time_grid + vol * B_t)\n",
    "        \n",
    "        # Step 2e: Determine Payoff\n",
    "        min_S_t = np.min(S_t)\n",
    "        ratio_min = min_S_t / s0\n",
    "        print(f\"Minimum Asset Price During Path: {min_S_t:.4f}\")\n",
    "        print(f\"Ratio_Min: {ratio_min:.4f}\")\n",
    "        \n",
    "        if ratio_min >= ki_barrier:\n",
    "            payoff = 0.10  # fulldummy\n",
    "            print(f\"min(S(t)) >= ki_barrier ({ki_barrier}) --> Payoff: {payoff}\")\n",
    "        else:\n",
    "            payoff = -0.10  # loss_coupon\n",
    "            print(f\"min(S(t)) < ki_barrier ({ki_barrier}) --> Payoff: {payoff}\")\n",
    "        \n",
    "        # Plotting the Brownian Bridge Asset Price Path\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(time_grid, S_t, label='Asset Price Path (S(t))', color='blue')\n",
    "        plt.axhline(y=barrier, color='green', linestyle='--', label='Barrier (80%)')\n",
    "        plt.axhline(y=ki_barrier, color='red', linestyle='--', label='Lower Barrier (70%)')\n",
    "        plt.scatter([0, maturity], [s0, S_T], color='black', zorder=5, label='Start and End Points')\n",
    "        plt.title('Asset Price Path Using Brownian Bridge')\n",
    "        plt.xlabel('Time (Years)')\n",
    "        plt.ylabel('Asset Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "s0 = 1\n",
    "maturity = 1\n",
    "ki_barrier = 0.7\n",
    "barrier = 0.8\n",
    "drift = 0.02 - 0 - 0.5 * 0.3 ** 2  # rfr - div - 0.5 * sigma^2\n",
    "vol = 0.3\n",
    "dt = 1 / 250  # Assuming 250 trading days\n",
    "\n",
    "# Visualize a single simulation\n",
    "visualize_brownian_bridge_simulation(s0, maturity, ki_barrier, barrier, drift, vol, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfee17",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def run_multiple_simulations(nSim):\n",
    "    for _ in range(nSim):\n",
    "        visualize_brownian_bridge_simulation(s0, maturity, ki_barrier, barrier, drift, vol, dt)\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Run 3 simulations\n",
    "run_multiple_simulations(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd25e5a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "T = 1  # Total time\n",
    "time_grid = np.linspace(0, T, 500)  # Time points\n",
    "variance = (time_grid * (T - time_grid)) / T  # Variance at each time t\n",
    "\n",
    "# Plotting the variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_grid, variance, label='Variance of Brownian Bridge')\n",
    "plt.title('Variance of a Brownian Bridge Over Time')\n",
    "plt.xlabel('Time (t)')\n",
    "plt.ylabel('Variance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889f019",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# 1. Define Parameters for the Three Normal Distributions\n",
    "# Ensure means are within [0, 1]\n",
    "means = [0.2, 0.5, 0.8]          # Centers of the hills\n",
    "std_devs = [0.02, 0.08, 0.04]    # Standard deviations (left: pointy, middle: broad, right: less pointy)\n",
    "weights = [0.3, 0.4, 0.3]         # Weights for each component\n",
    "\n",
    "# 2. Create the Custom PDF\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pdf = np.zeros_like(x)\n",
    "\n",
    "for mean, std, weight in zip(means, std_devs, weights):\n",
    "    pdf += weight * norm.pdf(x, mean, std)\n",
    "\n",
    "# Normalize the PDF to ensure it integrates to 1 over [0,1]\n",
    "integral = simps(pdf, x)\n",
    "pdf /= integral\n",
    "\n",
    "# 3. Compute the CDF\n",
    "cdf = np.cumsum(pdf)\n",
    "cdf /= cdf[-1]  # Normalize CDF to 1\n",
    "\n",
    "# 4. Inverse Transform Sampling\n",
    "def sample_from_custom_pdf(cdf, x, num_samples):\n",
    "    # Generate uniform random numbers\n",
    "    u = np.random.uniform(0, 1, num_samples)\n",
    "    # Use interpolation to find the corresponding x values\n",
    "    samples = np.interp(u, cdf, x)\n",
    "    return samples\n",
    "\n",
    "# Generate Samples\n",
    "num_samples = 10000\n",
    "samples = sample_from_custom_pdf(cdf, x, num_samples)\n",
    "\n",
    "# 5. Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the PDF\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, pdf, label='Custom PDF')\n",
    "plt.title('Custom Probability Density Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the Histogram of Samples\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(samples, bins=50, density=True, alpha=0.6, color='g', label='Sampled Data')\n",
    "plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "plt.title('Histogram of Sampled Data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Verify the Number of Hills\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "peaks, _ = find_peaks(pdf, height=0.01)  # Adjust height threshold as needed\n",
    "print(f\"Number of peaks detected in the PDF: {len(peaks)}\")\n",
    "print(f\"Peak locations: {x[peaks]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210911e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import simps\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# 1. Define Parameters for the Three Normal Distributions\n",
    "means = [0.2, 0.5, 0.8]          # Centers of the hills\n",
    "std_devs = [0.02, 0.08, 0.04]    # Standard deviations\n",
    "weights = [0.3, 0.4, 0.3]         # Weights for each component\n",
    "\n",
    "# 2. Create the Custom PDF\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pdf = np.zeros_like(x)\n",
    "\n",
    "for mean, std, weight in zip(means, std_devs, weights):\n",
    "    pdf += weight * norm.pdf(x, mean, std)\n",
    "\n",
    "# Normalize the PDF to ensure it integrates to 1 over [0,1]\n",
    "integral = simps(pdf, x)\n",
    "pdf /= integral\n",
    "\n",
    "# 3. Compute the CDF\n",
    "cdf = np.cumsum(pdf)\n",
    "cdf /= cdf[-1]  # Normalize CDF to 1\n",
    "\n",
    "# 4. Inverse Transform Sampling Function\n",
    "def sample_from_custom_pdf(cdf, x, num_samples):\n",
    "    # Generate uniform random numbers\n",
    "    u = np.random.uniform(0, 1, num_samples)\n",
    "    # Use interpolation to find the corresponding x values\n",
    "    samples = np.interp(u, cdf, x)\n",
    "    return samples\n",
    "\n",
    "# 5. Generate a Large Population (e.g., 200,000 samples)\n",
    "population_size = 200000\n",
    "population = sample_from_custom_pdf(cdf, x, population_size)\n",
    "\n",
    "# 6. Perform Uniform Random Sampling (n=1000)\n",
    "n_samples = 1000\n",
    "uniform_samples = np.random.choice(population, size=n_samples, replace=False)\n",
    "\n",
    "# 7. Create 10 Strata Based on the CDF\n",
    "strata_cdf_values = np.linspace(0.1, 0.9, 9)  # 0.1, 0.2, ..., 0.9\n",
    "strata_thresholds = np.interp(strata_cdf_values, cdf, x)\n",
    "strata_thresholds = np.concatenate(([0], strata_thresholds, [1]))  # Include 0 and 1\n",
    "\n",
    "# Display Strata Thresholds\n",
    "print(\"Strata Thresholds:\")\n",
    "for i in range(10):\n",
    "    print(f\"Stratum {i+1}: [{strata_thresholds[i]:.4f}, {strata_thresholds[i+1]:.4f})\")\n",
    "\n",
    "# 8. Calculate Stratum Weights\n",
    "stratum_counts = []\n",
    "stratum_weights = []\n",
    "for i in range(10):\n",
    "    lower = strata_thresholds[i]\n",
    "    upper = strata_thresholds[i+1]\n",
    "    count = np.sum((population >= lower) & (population < upper))\n",
    "    stratum_counts.append(count)\n",
    "    stratum_weights.append(count / population_size)\n",
    "\n",
    "# Display Stratum Weights\n",
    "print(\"\\nStratum Weights:\")\n",
    "for i, weight in enumerate(stratum_weights):\n",
    "    print(f\"Stratum {i+1}: {weight:.4f}\")\n",
    "\n",
    "# 9. Perform Stratified Sampling (n=1000)\n",
    "stratified_samples = []\n",
    "samples_per_stratum = np.round(n_samples * np.array(stratum_weights)).astype(int)\n",
    "\n",
    "# Adjust to ensure total samples equal to n_samples\n",
    "difference = n_samples - samples_per_stratum.sum()\n",
    "if difference > 0:\n",
    "    samples_per_stratum[:difference] += 1\n",
    "elif difference < 0:\n",
    "    samples_per_stratum[:abs(difference)] -= 1\n",
    "\n",
    "for i in range(10):\n",
    "    lower = strata_thresholds[i]\n",
    "    upper = strata_thresholds[i+1]\n",
    "    stratum_data = population[(population >= lower) & (population < upper)]\n",
    "    if len(stratum_data) == 0:\n",
    "        continue  # Skip if no data in stratum\n",
    "    samples_needed = samples_per_stratum[i]\n",
    "    if samples_needed > len(stratum_data):\n",
    "        # If not enough data, sample with replacement\n",
    "        sampled = np.random.choice(stratum_data, size=samples_needed, replace=True)\n",
    "    else:\n",
    "        sampled = np.random.choice(stratum_data, size=samples_needed, replace=False)\n",
    "    stratified_samples.extend(sampled)\n",
    "\n",
    "stratified_samples = np.array(stratified_samples)\n",
    "\n",
    "# 10. Visualization and Comparison\n",
    "\n",
    "# Compute Statistics\n",
    "population_mean = np.mean(population)\n",
    "uniform_mean = np.mean(uniform_samples)\n",
    "stratified_mean = np.mean(stratified_samples)\n",
    "\n",
    "print(f\"\\nPopulation Mean: {population_mean:.4f}\")\n",
    "print(f\"Uniform Sampling Mean: {uniform_mean:.4f}\")\n",
    "print(f\"Stratified Sampling Mean: {stratified_mean:.4f}\")\n",
    "\n",
    "# Plot Histograms\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histogram for Uniform Sampling\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(uniform_samples, bins=50, density=True, alpha=0.6, color='blue', label='Uniform Samples')\n",
    "plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "plt.title('Uniform Random Sampling vs Custom PDF')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "# Histogram for Stratified Sampling\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(stratified_samples, bins=50, density=True, alpha=0.6, color='green', label='Stratified Samples')\n",
    "plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "plt.title('Stratified Sampling vs Custom PDF')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional Visualization: Compare Sampling Distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(population, bins=100, density=True, alpha=0.3, label='Population', color='gray')\n",
    "plt.hist(uniform_samples, bins=50, density=True, alpha=0.6, label='Uniform Samples', color='blue')\n",
    "plt.hist(stratified_samples, bins=50, density=True, alpha=0.6, label='Stratified Samples', color='green')\n",
    "plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "plt.title('Comparison of Sampling Methods')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 11. Verify the Number of Hills in the Population PDF\n",
    "peaks, _ = find_peaks(pdf, height=0.005)  # Adjust height threshold as needed\n",
    "print(f\"\\nNumber of peaks detected in the PDF: {len(peaks)}\")\n",
    "print(f\"Peak locations: {x[peaks]}\")\n",
    "\n",
    "# 12. Verify the Number of Hills in Sampling PDFs\n",
    "# Function to detect peaks\n",
    "def detect_peaks(data, title):\n",
    "    hist, bin_edges = np.histogram(data, bins=50, range=(0,1), density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    peaks, _ = find_peaks(hist, height=0.005)\n",
    "    plt.plot(bin_centers, hist, label='Histogram')\n",
    "    plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "    plt.plot(bin_centers[peaks], hist[peaks], \"x\", label='Peaks')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(f\"Number of peaks detected: {len(peaks)} at locations: {bin_centers[peaks]}\")\n",
    "\n",
    "# Detect peaks in Uniform Sampling\n",
    "detect_peaks(uniform_samples, 'Uniform Sampling Histogram with Peaks')\n",
    "\n",
    "# Detect peaks in Stratified Sampling\n",
    "detect_peaks(stratified_samples, 'Stratified Sampling Histogram with Peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44395e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratum_counts # cdf에서 equal하게 잘랐으므로, 각 stratum의 count가 비슷할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6f63c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 13. Define Equal-Width Strata\n",
    "equal_width_strata = np.linspace(0, 1, 11)  # 0.0, 0.1, 0.2, ..., 1.0\n",
    "\n",
    "# 14. Perform Equal-Width Stratified Sampling (n=1000, 100 per stratum)\n",
    "equal_width_samples = []\n",
    "samples_per_stratum_eq = 100  # 100 samples per stratum\n",
    "\n",
    "for i in range(10):\n",
    "    lower = equal_width_strata[i]\n",
    "    upper = equal_width_strata[i+1]\n",
    "    # Extract population data within the current stratum\n",
    "    stratum_data_eq = population[(population >= lower) & (population < upper)]\n",
    "    if len(stratum_data_eq) == 0:\n",
    "        # If no data in stratum, skip sampling\n",
    "        continue\n",
    "    # Sample uniformly within the stratum\n",
    "    # If insufficient data, sample with replacement\n",
    "    if len(stratum_data_eq) < samples_per_stratum_eq:\n",
    "        sampled_eq = np.random.choice(stratum_data_eq, size=samples_per_stratum_eq, replace=True)\n",
    "    else:\n",
    "        sampled_eq = np.random.choice(stratum_data_eq, size=samples_per_stratum_eq, replace=False)\n",
    "    equal_width_samples.extend(sampled_eq)\n",
    "\n",
    "equal_width_samples = np.array(equal_width_samples)\n",
    "\n",
    "# 15. Plot the Histogram Comparing Equal-Width Stratified Sampling with Custom PDF\n",
    "\n",
    "# Compute histogram data\n",
    "hist_eq, bin_edges_eq = np.histogram(equal_width_samples, bins=50, range=(0,1), density=True)\n",
    "bin_centers_eq = (bin_edges_eq[:-1] + bin_edges_eq[1:]) / 2\n",
    "\n",
    "# Detect peaks in the histogram\n",
    "peaks_eq, properties_eq = find_peaks(hist_eq, height=0.005)  # Adjust height threshold as needed\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "# Plot the histogram of equal-width stratified samples as a blue line\n",
    "plt.plot(bin_centers_eq, hist_eq, color='blue', label='Equal-Width Stratified Samples')\n",
    "\n",
    "# Overlay the custom PDF in red\n",
    "plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "\n",
    "# Mark the peaks with 'x' markers in black\n",
    "plt.plot(bin_centers_eq[peaks_eq], hist_eq[peaks_eq], \"x\", color='black', label='Peaks')\n",
    "\n",
    "# Set x-axis limits to [0,1] to ensure the PDF is bounded correctly\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "plt.title('Equal-Width Stratified Sampling vs Custom PDF')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 16. Print Peak Information (Optional)\n",
    "print(f\"Number of peaks detected in Equal-Width Stratified Sampling Histogram: {len(peaks_eq)}\")\n",
    "print(f\"Peak locations: {bin_centers_eq[peaks_eq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c97892",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "# 13. Redefine the Custom PDF using Truncated Normal Distributions\n",
    "def get_truncnorm_pdf(mean, std, x, lower=0, upper=1):\n",
    "    \"\"\"\n",
    "    Returns the PDF of a truncated normal distribution at points x.\n",
    "    \"\"\"\n",
    "    a, b = (lower - mean) / std, (upper - mean) / std\n",
    "    trunc_pdf = truncnorm.pdf(x, a, b, loc=mean, scale=std)\n",
    "    return trunc_pdf\n",
    "\n",
    "# Reset the PDF\n",
    "pdf = np.zeros_like(x)\n",
    "\n",
    "# Create the truncated normal components and sum them\n",
    "for mean, std, weight in zip(means, std_devs, weights):\n",
    "    trunc_pdf = weight * get_truncnorm_pdf(mean, std, x)\n",
    "    pdf += trunc_pdf\n",
    "\n",
    "# Normalize the PDF to ensure it integrates to 1 over [0,1]\n",
    "integral = simps(pdf, x)\n",
    "pdf /= integral\n",
    "\n",
    "# 14. Recompute the CDF with the Updated PDF\n",
    "cdf = np.cumsum(pdf)\n",
    "cdf /= cdf[-1]  # Normalize CDF to 1\n",
    "\n",
    "# 15. Regenerate the Population with the Corrected PDF\n",
    "population = sample_from_custom_pdf(cdf, x, population_size)\n",
    "\n",
    "# 16. Recalculate Strata Thresholds Based on the New CDF\n",
    "strata_cdf_values = np.linspace(0.1, 0.9, 9)  # 0.1, 0.2, ..., 0.9\n",
    "strata_thresholds = np.interp(strata_cdf_values, cdf, x)\n",
    "strata_thresholds = np.concatenate(([0], strata_thresholds, [1]))  # Include 0 and 1\n",
    "\n",
    "# Display Updated Strata Thresholds\n",
    "print(\"\\nUpdated Strata Thresholds:\")\n",
    "for i in range(10):\n",
    "    print(f\"Stratum {i+1}: [{strata_thresholds[i]:.4f}, {strata_thresholds[i+1]:.4f})\")\n",
    "\n",
    "# 17. Recalculate Stratum Weights with the New Population\n",
    "stratum_counts = []\n",
    "stratum_weights = []\n",
    "for i in range(10):\n",
    "    lower = strata_thresholds[i]\n",
    "    upper = strata_thresholds[i+1]\n",
    "    count = np.sum((population >= lower) & (population < upper))\n",
    "    stratum_counts.append(count)\n",
    "    stratum_weights.append(count / population_size)\n",
    "\n",
    "# Display Updated Stratum Weights\n",
    "print(\"\\nUpdated Stratum Weights:\")\n",
    "for i, weight in enumerate(stratum_weights):\n",
    "    print(f\"Stratum {i+1}: {weight:.4f}\")\n",
    "\n",
    "# 18. Re-perform Stratified Sampling with the Corrected Population and Weights\n",
    "stratified_samples = []\n",
    "samples_per_stratum = np.round(n_samples * np.array(stratum_weights)).astype(int)\n",
    "\n",
    "# Adjust to ensure total samples equal to n_samples\n",
    "difference = n_samples - samples_per_stratum.sum()\n",
    "if difference > 0:\n",
    "    samples_per_stratum[:difference] += 1\n",
    "elif difference < 0:\n",
    "    samples_per_stratum[:abs(difference)] -= 1\n",
    "\n",
    "for i in range(10):\n",
    "    lower = strata_thresholds[i]\n",
    "    upper = strata_thresholds[i+1]\n",
    "    stratum_data = population[(population >= lower) & (population < upper)]\n",
    "    if len(stratum_data) == 0:\n",
    "        continue  # Skip if no data in stratum\n",
    "    samples_needed = samples_per_stratum[i]\n",
    "    if samples_needed > len(stratum_data):\n",
    "        # If not enough data, sample with replacement\n",
    "        sampled = np.random.choice(stratum_data, size=samples_needed, replace=True)\n",
    "    else:\n",
    "        sampled = np.random.choice(stratum_data, size=samples_needed, replace=False)\n",
    "    stratified_samples.extend(sampled)\n",
    "\n",
    "stratified_samples = np.array(stratified_samples)\n",
    "\n",
    "# 19. Define Chunk Size and Initialize Lists for Modified PDF\n",
    "chunks_per_merge = 4  # Number of small chunks to merge into one\n",
    "small_chunk_size = 0.005  # Original small chunk size\n",
    "\n",
    "# Initialize lists to store small chunk centers and their probabilities\n",
    "small_chunk_centers = []\n",
    "small_chunk_probabilities = []\n",
    "\n",
    "# Divide Each Stratum into Small Chunks and Assign Probabilities Based on PDF Density\n",
    "for i in range(10):\n",
    "    lower = strata_thresholds[i]\n",
    "    upper = strata_thresholds[i+1]\n",
    "    stratum_weight = stratum_weights[i]\n",
    "    \n",
    "    # Calculate the number of full small chunks within the stratum\n",
    "    num_full_small_chunks = int((upper - lower) // small_chunk_size)\n",
    "    \n",
    "    # Calculate remaining range after full small chunks\n",
    "    remaining_small = (upper - lower) - (num_full_small_chunks * small_chunk_size)\n",
    "    \n",
    "    # Total number of small chunks (including the last partial chunk if any)\n",
    "    total_small_chunks = num_full_small_chunks + (1 if remaining_small > 1e-8 else 0)\n",
    "    \n",
    "    # Assign probability per small chunk based on PDF density\n",
    "    for j in range(total_small_chunks):\n",
    "        chunk_lower = lower + j * small_chunk_size\n",
    "        chunk_upper = chunk_lower + small_chunk_size\n",
    "        if j == total_small_chunks - 1 and remaining_small > 1e-8:\n",
    "            # Last chunk may be smaller\n",
    "            chunk_upper = upper\n",
    "            actual_chunk_size = chunk_upper - chunk_lower\n",
    "        else:\n",
    "            actual_chunk_size = small_chunk_size\n",
    "        \n",
    "        # Calculate chunk center\n",
    "        chunk_center = chunk_lower + actual_chunk_size / 2\n",
    "        small_chunk_centers.append(chunk_center)\n",
    "        \n",
    "        # Compute the integral of the PDF over the small chunk using Simpson's rule\n",
    "        chunk_x = np.linspace(chunk_lower, chunk_upper, 100)  # 100 points per small chunk for accuracy\n",
    "        chunk_pdf = np.interp(chunk_x, x, pdf)\n",
    "        chunk_integral = simps(chunk_pdf, chunk_x)\n",
    "        \n",
    "        # Assign the small chunk's probability\n",
    "        small_chunk_probabilities.append(chunk_integral)\n",
    "\n",
    "# 20. Merge Every 4 Small Chunks into 1 Larger Chunk\n",
    "total_small_chunks = len(small_chunk_centers)\n",
    "if total_small_chunks % chunks_per_merge != 0:\n",
    "    # If not divisible, trim the excess small chunks\n",
    "    excess = total_small_chunks % chunks_per_merge\n",
    "    small_chunk_centers = small_chunk_centers[:-excess]\n",
    "    small_chunk_probabilities = small_chunk_probabilities[:-excess]\n",
    "    total_small_chunks = len(small_chunk_centers)\n",
    "\n",
    "# Reshape the small chunks into groups of 4\n",
    "small_chunk_centers_reshaped = np.array(small_chunk_centers).reshape(-1, chunks_per_merge)\n",
    "small_chunk_probabilities_reshaped = np.array(small_chunk_probabilities).reshape(-1, chunks_per_merge)\n",
    "\n",
    "# Calculate merged chunk centers and probabilities\n",
    "merged_chunk_centers = small_chunk_centers_reshaped.mean(axis=1)\n",
    "merged_chunk_probabilities = small_chunk_probabilities_reshaped.sum(axis=1) / (chunks_per_merge * small_chunk_size)\n",
    "\n",
    "# 21. Plot the Modified Probability Distribution After Stratification (50 Bins)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the original custom PDF in red\n",
    "plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "\n",
    "# Plot the modified PDF after stratification in blue\n",
    "plt.plot(merged_chunk_centers, merged_chunk_probabilities, 'b-', label='Modified PDF After Stratification (50 Bins)', )\n",
    "\n",
    "plt.title('Modified Probability Distribution After Stratified Sampling (50 Bins)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, max(pdf)*1.2)  # Adjust y-axis for better visibility\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 22. Verification of Total Probability\n",
    "total_prob_merged = merged_chunk_probabilities.sum() * (chunks_per_merge * small_chunk_size)\n",
    "print(f\"\\nTotal probability after stratification (50 chunks): {total_prob_merged:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd0f1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot the original custom PDF in red\n",
    "plt.plot(x, pdf, 'r-', label='Custom PDF')\n",
    "\n",
    "# Plot the modified PDF after stratification as a blue bar graph\n",
    "plt.bar(\n",
    "    merged_chunk_centers,                  # X-coordinates (centers of the merged chunks)\n",
    "    merged_chunk_probabilities,            # Heights of the bars (probability densities)\n",
    "    width=0.02,                            # Width of each bar (merged chunk size)\n",
    "    color='b',                             # Color of the bars\n",
    "    alpha=0.6,                             # Transparency of the bars\n",
    "    label='Modified PDF After Stratification (50 Bins)',\n",
    "    align='center'                         # Align bars to the center of x-coordinates\n",
    ")\n",
    "\n",
    "# Enhance the plot with titles and labels\n",
    "plt.title('Modified Probability Distribution After Stratified Sampling (50 Bins)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Set the limits for better visualization\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, max(pdf)*1.2)  # Adjust y-axis to accommodate the highest probability\n",
    "\n",
    "# Adjust layout for neatness and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7883f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
