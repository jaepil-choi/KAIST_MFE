{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457b8969",
   "metadata": {},
   "source": [
    "# 거래소에서 option data 가져와보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0653a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo  # Python 3.9 이상\n",
    "\n",
    "from typing import List, Tuple \n",
    "from tqdm import tqdm\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793de501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CWD_PATH = Path.cwd()\n",
    "DATA_PATH = CWD_PATH / 'data'\n",
    "BACKUP_PATH = CWD_PATH / 'backup'\n",
    "OUTPUT_PATH = CWD_PATH / 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b06d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac26bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom libs\n",
    "\n",
    "from krx_config import API_URL, HEADERS, PAYLOAD_TEMPLATE, PAYLOAD_OPTION_HOME, HEADERS_OPTION_HOME, PAYLOAD_TEMPLATE2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895bf9c2",
   "metadata": {},
   "source": [
    "## API scraping code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d994225",
   "metadata": {},
   "source": [
    "### Prompt 1\n",
    "\n",
    "I need to write code to scrape data from KRX(한국거래소) website. The website uses POST to get daily snapshot of all the options traded on that day. \n",
    "\n",
    "Below is the information for its endpint (getJsonData.cmd) and what are in the headers and what the payload is and what the response looks like. \n",
    "\n",
    "Write Python code that takes start date and end date as an input and iteratively get the option price data from the api. \n",
    "\n",
    "You should make the requests to look like human by setting web browser user-agent and other stuff that can be detected by site admin. \n",
    "\n",
    "Although, you don't have to use dynamic scraping like selenium because as you can see, we're communicating with an API in restful way, with POST method. \n",
    "\n",
    "When you write the code, make the code modular and keep the function document as simple as possible. Never make verbose docstring that can bloat the code with unnecessary details. \n",
    "\n",
    "Below are the information that you need to write the correct API call scraper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_range(start_date: str, end_date: str) -> List[str]: \n",
    "    \"\"\"\n",
    "    종료일(end_date)부터 시작일(start_date)까지의 비주말(평일) 날짜를 YYYYMMDD 형식으로 반환합니다.\n",
    "    날짜는 한국 서울 시간대 기준입니다.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): 시작 날짜 ('YYYY-MM-DD' 형식).\n",
    "        end_date (str): 종료 날짜 ('YYYY-MM-DD' 형식).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: 내림차순으로 정렬된 비주말 날짜 리스트 ('YYYYMMDD' 형식).\n",
    "    \"\"\"\n",
    "    tz = ZoneInfo('Asia/Seoul')\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    delta = end - start\n",
    "    date_list = []\n",
    "    for i in range(delta.days + 1):\n",
    "        current_date = end - timedelta(days=i)\n",
    "        if current_date.weekday() < 5:  # 0-4는 월요일~금요일\n",
    "            date_list.append(current_date.strftime(\"%Y%m%d\"))\n",
    "    return date_list\n",
    "\n",
    "def fetch_option_data(session: requests.Session, trade_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches option data for a specific trade date.\n",
    "\n",
    "    Args:\n",
    "        session (requests.Session): The requests session with headers set.\n",
    "        trade_date (str): Trade date in 'YYYYMMDD' format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing option data for the trade date.\n",
    "    \"\"\"\n",
    "    payload = PAYLOAD_TEMPLATE.copy()\n",
    "    payload[\"trdDd\"] = trade_date\n",
    "\n",
    "    response = session.post(API_URL, data=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    if \"output\" not in data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(data[\"output\"])\n",
    "\n",
    "def scrape_krx_option_data(start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrapes KRX option data between start_date and end_date.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame containing option data for all dates.\n",
    "    \"\"\"\n",
    "    dates = generate_date_range(start_date, end_date)\n",
    "    all_data = []\n",
    "\n",
    "    with requests.Session() as session:\n",
    "        session.headers.update(HEADERS)\n",
    "        for date in tqdm(dates, desc=\"Fetching data\"):\n",
    "            try:\n",
    "                daily_data = fetch_option_data(session, date)\n",
    "                if not daily_data.empty:\n",
    "                    daily_data['Trade_Date'] = datetime.strptime(date, \"%Y%m%d\").date()\n",
    "                    all_data.append(daily_data)\n",
    "                time.sleep(1)  # Delay to mimic human behavior\n",
    "            except requests.HTTPError as http_err:\n",
    "                print(f\"HTTP error for date {date}: {http_err}\")\n",
    "            except Exception as err:\n",
    "                print(f\"Error for date {date}: {err}\")\n",
    "\n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_to_excel(df: pd.DataFrame, filename: str):\n",
    "    \"\"\"\n",
    "    Saves the DataFrame to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to save.\n",
    "        filename (str): Filename for the Excel file.\n",
    "    \"\"\"\n",
    "    df.to_excel(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_date = '20241204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e98327",
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.Session() as session:\n",
    "    session.headers.update(HEADERS)\n",
    "    payload = PAYLOAD_TEMPLATE.copy()\n",
    "    payload[\"trdDd\"] = sample_date\n",
    "\n",
    "    response = session.post(API_URL, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a07e22",
   "metadata": {},
   "source": [
    "거래소 주식 옵션 전체로 조회하는거 막혔음. 나만 막힌게 아니고 전부. \n",
    "\n",
    "하지만 개별 underlying 종목을 설정해서 조회할 경우 불러올 수 있음. 딱 1년치만 불러오자. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad7353",
   "metadata": {},
   "source": [
    "### 개별 주식 옵션 데이터 불러오기 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00554aaf",
   "metadata": {},
   "source": [
    "또 막힐 수 있으니까 일단 삼성만 1년치 불러오고 나머지는 다시 하는걸로? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거래소 주식 옵션 종목들 조회 \n",
    "\n",
    "with requests.Session() as session:\n",
    "    session.headers.update(HEADERS_OPTION_HOME)\n",
    "    payload = PAYLOAD_OPTION_HOME.copy()\n",
    "    response = session.post(API_URL, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df102a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_underlyings = pd.DataFrame(response.json()['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b615809",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_underlyings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(available_underlyings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28578a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_under_code_list = available_underlyings['value'].tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_elec = 'KRDRVOPS11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 종목 call 되나 확인 \n",
    "\n",
    "with requests.Session() as session:\n",
    "    session.headers.update(HEADERS)\n",
    "    payload = PAYLOAD_TEMPLATE2.copy()\n",
    "    \n",
    "    payload['trdDd'] = sample_date\n",
    "    payload['trdDdBox1'] = sample_date\n",
    "    payload['trdDdBox2'] = sample_date\n",
    "    \n",
    "    payload[\"ulyId\"] = samsung_elec\n",
    "\n",
    "    response = session.post(API_URL, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1 = pd.DataFrame(response.json()['output'])\n",
    "len(dd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0cafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 종목 call, 기간 줘도 되나 확인. \n",
    "\n",
    "with requests.Session() as session:\n",
    "    session.headers.update(HEADERS)\n",
    "    payload = PAYLOAD_TEMPLATE2.copy()\n",
    "    \n",
    "    payload['trdDd'] = sample_date\n",
    "    payload['trdDdBox1'] = '20241202'\n",
    "    payload['trdDdBox2'] = sample_date\n",
    "    \n",
    "    payload[\"ulyId\"] = samsung_elec\n",
    "\n",
    "    response = session.post(API_URL, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = pd.DataFrame(response.json()['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6363c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trdDdBox1, trdDdBox2 는 그냥 deprecated된 legacy parameter로 보인다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367aeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 종목 call, 기간 줘도 되나 확인. \n",
    "\n",
    "with requests.Session() as session:\n",
    "    session.headers.update(HEADERS)\n",
    "    payload = PAYLOAD_TEMPLATE2.copy()\n",
    "    \n",
    "    payload['trdDd'] = \"\" # 빠지면 안됨.\n",
    "    payload['trdDdBox1'] = '20241202'\n",
    "    payload['trdDdBox2'] = sample_date\n",
    "    \n",
    "    payload[\"ulyId\"] = samsung_elec\n",
    "\n",
    "    response = session.post(API_URL, data=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f8ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd3 = pd.DataFrame(response.json()['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dd3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83875d",
   "metadata": {},
   "source": [
    "### 개별 주식 옵션 데이터 불러와서 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45b2af",
   "metadata": {},
   "source": [
    "일단 테스트로 삼성만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9351a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_option_data1(session: requests.Session, uly_code: str, trade_date: str,) -> pd.DataFrame:\n",
    "    payload = PAYLOAD_TEMPLATE.copy()\n",
    "    \n",
    "    payload[\"trdDd\"] = trade_date\n",
    "    payload['trdDdBox1'] = trade_date\n",
    "    payload['trdDdBox2'] = trade_date\n",
    "\n",
    "    payload[\"ulyId\"] = uly_code\n",
    "\n",
    "    response = session.post(API_URL, data=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    if \"output\" not in data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(data[\"output\"])\n",
    "\n",
    "def scrape_krx_option_data1(start_date: str, end_date: str, ulycode_list: list) -> pd.DataFrame:\n",
    "    dates = generate_date_range(start_date, end_date)\n",
    "    \n",
    "    all_data = []\n",
    "    for uly_code in ulycode_list:\n",
    "        with requests.Session() as session:\n",
    "            session.headers.update(HEADERS)\n",
    "            for date in tqdm(dates, desc=\"Fetching data\"):\n",
    "                try:\n",
    "                    daily_data = fetch_option_data(session, uly_code, date)\n",
    "                    if not daily_data.empty:\n",
    "                        daily_data['Trade_Date'] = datetime.strptime(date, \"%Y%m%d\").date()\n",
    "                        daily_data['Uly_Code'] = uly_code\n",
    "                        all_data.append(daily_data)\n",
    "                    time.sleep(3)  # Delay to mimic human behavior\n",
    "                except requests.HTTPError as http_err:\n",
    "                    print(f\"HTTP error for date {date}: {http_err}\")\n",
    "                except Exception as err:\n",
    "                    print(f\"Error for date {date}: {err}\")\n",
    "\n",
    "    if all_data:\n",
    "        return pd.concat(all_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2024-01-01'\n",
    "end = '2024-12-04'\n",
    "\n",
    "samsung_list = [samsung_elec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9831a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df = scrape_krx_option_data1(start, end, samsung_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df.to_pickle(DATA_PATH / 'samsung_option.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cea550",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samsung_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df = pd.read_pickle(DATA_PATH / 'samsung_option.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fed044",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strike price 등의 정보를 이름에서 파싱 \n",
    "\n",
    "import re\n",
    "\n",
    "def parse_option_name(option_name):\n",
    "    pattern = r\"(?P<underlying>[\\w가-힣]+)\\s+(?P<call_or_put>[CP])\\s+(?P<expiration>\\d{6})\\s+(?P<strike>[\\d,]+)\\(\\s*(?P<multiplier>\\d+)\\)\"\n",
    "\n",
    "    # Match the pattern\n",
    "    match = re.match(pattern, option_name)\n",
    "\n",
    "    # Extract data if a match is found\n",
    "    if match:\n",
    "        data = {\n",
    "            \"underlying\": match.group(\"underlying\"),\n",
    "            \"call_or_put\": match.group(\"call_or_put\"),\n",
    "            \"expiration\": match.group(\"expiration\"),\n",
    "            \"strike\": float(match.group(\"strike\").replace(\",\", \"\")),\n",
    "            \"multiplier\": int(match.group(\"multiplier\")),\n",
    "        }\n",
    "\n",
    "        return data\n",
    "        \n",
    "    else:\n",
    "        data = {\n",
    "            \"underlying\": None,\n",
    "            \"call_or_put\": None,\n",
    "            \"expiration\": None,\n",
    "            \"strike\": None,\n",
    "            \"multiplier\": None,\n",
    "        }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfdb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = samsung_df['ISU_NM'].apply(parse_option_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = pd.DataFrame(parsed_data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b47ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df = pd.concat([samsung_df, parsed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_name = {\n",
    "    'ISU_CD': 'option_sid(full)',  # 종목코드(full)\n",
    "    'ISU_SRT_CD': 'option_sid(short)',  # 종목코드(short)\n",
    "    'ISU_NM': 'option_name',  # 종목명\n",
    "    'TDD_CLSPRC': 'close_price',  # 종가\n",
    "    'FLUC_TP_CD': 'up_or_down',  # 등락구분\n",
    "    'CMPPREVDD_PRC': 'price_change',  # 대비\n",
    "    'TDD_OPNPRC': 'open_price',  # 시가\n",
    "    'TDD_HGPRC': 'high_price',  # 고가\n",
    "    'TDD_LWPRC': 'low_price',  # 저가\n",
    "    'IMP_VOLT': 'im_vol',  # 내재변동성\n",
    "    'NXTDD_BAS_PRC': 'next_day_base_price',  # 익일기준가\n",
    "    'ACC_TRDVOL': 'trade_volume',  # 거래량\n",
    "    'ACC_TRDVAL': 'trade_value',  # 거래대금\n",
    "    'ACC_OPNINT_QTY': 'open_interest_quantity',  # 미결제약정수량\n",
    "    'SECUGRP_ID': 'security_type',  # 증권유형\n",
    "    'Trade_Date': 'trade_date',  # 거래일자\n",
    "    'Uly_Code': 'underlying_code',  # 기초자산코드\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042b307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df.rename(columns=column_to_name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [\n",
    "    'close_price', 'price_change', 'open_price', 'high_price', 'low_price',\n",
    "    'im_vol', 'next_day_base_price', 'trade_volume', 'trade_value',\n",
    "    'open_interest_quantity', \n",
    "    'expiration', \n",
    "    'up_or_down',\n",
    "    # 'strike', \n",
    "    # 'multiplier',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686dc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for float_col in float_cols:\n",
    "    print(f'converting {float_col} to numeric')\n",
    "    samsung_df[float_col] = samsung_df[float_col].str.replace('-', '')\n",
    "    samsung_df[float_col] = samsung_df[float_col].str.replace(',', '')\n",
    "    samsung_df[float_col] = pd.to_numeric(samsung_df[float_col], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df['trade_date'] = pd.to_datetime(samsung_df['trade_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2065bd",
   "metadata": {},
   "source": [
    "데이터를 처리하기 쉬운 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a708d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\n",
    "    'underlying',\n",
    "    'call_or_put',\n",
    "    'expiration',\n",
    "    'trade_date',\n",
    "    'strike',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_cols = [\n",
    "    'close_price',\n",
    "    'open_price',\n",
    "    'high_price',\n",
    "    'low_price',\n",
    "    'im_vol',\n",
    "    'next_day_base_price',\n",
    "    'trade_volume',\n",
    "    'trade_value',\n",
    "    'open_interest_quantity',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b24ce4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "samsung_final_df = samsung_df[index_cols + value_cols].copy()\n",
    "samsung_final_df.set_index(index_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_final_df.to_pickle(DATA_PATH / 'samsung_option_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32898811",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2021-01-01'\n",
    "END_DATE = '2024-12-05'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d840d6",
   "metadata": {},
   "source": [
    "\n",
    "### New Prompt\n",
    "\n",
    "Implement retry strategy in this code. \n",
    "Retry strategy should:\n",
    "- when there's bad requests like 400, step back and wait and retry. \n",
    "\n",
    "You should suggest me additional measure to avoid getting blocked. Is there a free VPN service that I can use to hide my identity? \n",
    "\n",
    "Also, to avoid losing all the data when I get blocked, write the code to:\n",
    "\n",
    "- start from end date to start date\n",
    "- for each date scraped, save it in the data by appending the data (not overwriting). You should use h5py to save it in h5 format to append the data. \n",
    "- periodically (per 100 scrape) copy that h5 file to somewhere else for me to safely use it without racing condition. ( I will copy the copy of the h5 and use it at somewhere else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdf67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import os\n",
    "import shutil\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "from zoneinfo import ZoneInfo  # Python 3.9 이상\n",
    "\n",
    "# Import configurations\n",
    "from krx_config import API_URL, HEADERS, PAYLOAD_TEMPLATE\n",
    "\n",
    "\n",
    "\n",
    "# Constants for backup\n",
    "BACKUP_INTERVAL = 100  # Backup after every 100 successful scrapes\n",
    "H5_FILE = DATA_PATH / \"krx_option_data.h5\"\n",
    "\n",
    "def generate_date_range(start_date: str, end_date: str) -> List[str]: \n",
    "    \"\"\"\n",
    "    종료일(end_date)부터 시작일(start_date)까지의 비주말(평일) 날짜를 YYYYMMDD 형식으로 반환합니다.\n",
    "    날짜는 한국 서울 시간대 기준입니다.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): 시작 날짜 ('YYYY-MM-DD' 형식).\n",
    "        end_date (str): 종료 날짜 ('YYYY-MM-DD' 형식).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: 내림차순으로 정렬된 비주말 날짜 리스트 ('YYYYMMDD' 형식).\n",
    "    \"\"\"\n",
    "    tz = ZoneInfo('Asia/Seoul')\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    delta = end - start\n",
    "    date_list = []\n",
    "    for i in range(delta.days + 1):\n",
    "        current_date = end - timedelta(days=i)\n",
    "        if current_date.weekday() < 5:  # 0-4는 월요일~금요일\n",
    "            date_list.append(current_date.strftime(\"%Y%m%d\"))\n",
    "    return date_list\n",
    "\n",
    "def setup_session() -> requests.Session:\n",
    "    \"\"\"\n",
    "    Sets up a requests session with headers and retry strategy.\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.headers.update(HEADERS)\n",
    "    \n",
    "    retry_strategy = Retry(\n",
    "        total=5,\n",
    "        status_forcelist=[400, 429, 500, 502, 503, 504],\n",
    "        method_whitelist=[\"POST\"],\n",
    "        backoff_factor=1\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    \n",
    "    return session\n",
    "\n",
    "def fetch_option_data(session: requests.Session, trade_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches option data for a specific trade date.\n",
    "    \"\"\"\n",
    "    payload = PAYLOAD_TEMPLATE.copy()\n",
    "    payload[\"trdDd\"] = trade_date\n",
    "\n",
    "    response = session.post(API_URL, data=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    if \"output\" not in data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(data[\"output\"])\n",
    "\n",
    "def save_data_h5(df: pd.DataFrame, filename: str):\n",
    "    \"\"\"\n",
    "    Appends DataFrame to an HDF5 file.\n",
    "    \"\"\"\n",
    "    with pd.HDFStore(filename, mode='a') as store:\n",
    "        store.append('option_data', df, format='table', data_columns=True)\n",
    "\n",
    "def backup_h5_file(source: str, backup_path: Path):\n",
    "    \"\"\"\n",
    "    Copies the HDF5 file to the backup directory with a timestamp.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    backup_path = BACKUP_PATH / f\"krx_option_data_backup_{timestamp}.h5\"\n",
    "    shutil.copy(source, backup_path)\n",
    "    print(f\"Backup created at {backup_path}\")\n",
    "\n",
    "def scrape_krx_option_data(start_date: str, end_date: str) -> None:\n",
    "    \"\"\"\n",
    "    Scrapes KRX option data between start_date and end_date and saves to HDF5.\n",
    "    Implements retry and backup strategies.\n",
    "    \"\"\"\n",
    "    dates = generate_date_range(start_date, end_date)\n",
    "    success_count = 0\n",
    "\n",
    "    session = setup_session()\n",
    "    \n",
    "    for date in tqdm(dates, desc=\"Fetching data\"):\n",
    "        try:\n",
    "            daily_data = fetch_option_data(session, date)\n",
    "            if not daily_data.empty:\n",
    "                daily_data['Trade_Date'] = datetime.strptime(date, \"%Y%m%d\").date()\n",
    "                save_data_h5(daily_data, H5_FILE)\n",
    "                success_count += 1\n",
    "                \n",
    "                if success_count % BACKUP_INTERVAL == 0:\n",
    "                    backup_h5_file(H5_FILE, BACKUP_PATH)\n",
    "            \n",
    "            time.sleep(1)  # Delay to mimic human behavior\n",
    "        except requests.HTTPError as http_err:\n",
    "            print(f\"HTTP error for date {date}: {http_err}\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "        except Exception as err:\n",
    "            print(f\"Error for date {date}: {err}\")\n",
    "            time.sleep(5)  # Wait before continuing\n",
    "    \n",
    "    # Final backup after completion\n",
    "    backup_h5_file(H5_FILE, BACKUP_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3734d66",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    START_DATE = \"2024-12-01\"\n",
    "    END_DATE = \"2024-12-06\"\n",
    "    \n",
    "    print(f\"Scraping KRX option data from {START_DATE} to {END_DATE}...\")\n",
    "    scrape_krx_option_data(START_DATE, END_DATE)\n",
    "    print(\"Scraping completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a88a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
