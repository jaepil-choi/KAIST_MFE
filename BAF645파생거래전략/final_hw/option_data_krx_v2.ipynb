{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0c8421",
   "metadata": {},
   "source": [
    "# 거래소에서 option data 가져와보기\n",
    "\n",
    "- daily snapshot으로 전 행사가, 전 만기를 가져올 수 있어 좋다. 데이터 양이 너무 많다는 것이 문제라면 문제 \n",
    "- 너무 많이 요청했을 때 차단 당한다. \n",
    "    - 차단 안당하게 충분히 sleep 넣어주고, retry도 multiplier 높여주기. \n",
    "    - 카이스트 ip 차단 방지하기 위해 피씨방에 돈 충전하고 크롤링은 parsec으로 원격으로 돌리기. \n",
    "- 차단/중단시 그동안 한거라도 건지기 위해 계속 h5로 append, copy하여 저장. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c49f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo  # Python 3.9 이상\n",
    "\n",
    "from typing import List, Tuple \n",
    "from tqdm import tqdm\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CWD_PATH = Path.cwd()\n",
    "DATA_PATH = CWD_PATH / 'data'\n",
    "BACKUP_PATH = CWD_PATH / 'backup'\n",
    "OUTPUT_PATH = CWD_PATH / 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed97eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom libs\n",
    "\n",
    "from krx_config import (\n",
    "API_URL, \n",
    "HEADERS, \n",
    "PAYLOAD_TEMPLATE, \n",
    "PAYLOAD_OPTION_HOME, \n",
    "HEADERS_OPTION_HOME, \n",
    "PAYLOAD_TEMPLATE2,\n",
    "H5_SCHEMA,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4e205",
   "metadata": {},
   "source": [
    "## Scraping code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a999425",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import os\n",
    "import shutil\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "from zoneinfo import ZoneInfo  # Python 3.9 이상\n",
    "\n",
    "# Import configurations\n",
    "from krx_config import API_URL, HEADERS, PAYLOAD_TEMPLATE\n",
    "\n",
    "\n",
    "\n",
    "# Constants for backup\n",
    "BACKUP_INTERVAL = 10  # Backup after every 100 successful scrapes\n",
    "H5_FILE = DATA_PATH / \"krx_option_data.h5\"\n",
    "\n",
    "def generate_date_range(start_date: str, end_date: str) -> List[str]: \n",
    "    \"\"\"\n",
    "    종료일(end_date)부터 시작일(start_date)까지의 비주말(평일) 날짜를 YYYYMMDD 형식으로 반환합니다.\n",
    "    날짜는 한국 서울 시간대 기준입니다.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): 시작 날짜 ('YYYY-MM-DD' 형식).\n",
    "        end_date (str): 종료 날짜 ('YYYY-MM-DD' 형식).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: 내림차순으로 정렬된 비주말 날짜 리스트 ('YYYYMMDD' 형식).\n",
    "    \"\"\"\n",
    "    tz = ZoneInfo('Asia/Seoul')\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    delta = end - start\n",
    "    date_list = []\n",
    "    for i in range(delta.days + 1):\n",
    "        current_date = end - timedelta(days=i)\n",
    "        if current_date.weekday() < 5:  # 0-4는 월요일~금요일\n",
    "            date_list.append(current_date.strftime(\"%Y%m%d\"))\n",
    "    return date_list\n",
    "\n",
    "def setup_session() -> requests.Session:\n",
    "    \"\"\"\n",
    "    Sets up a requests session with headers and retry strategy.\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.headers.update(HEADERS)\n",
    "    \n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[400, 429, 500, 502, 503, 504],\n",
    "        # method_whitelist=[\"POST\"], # Deprecated\n",
    "        allowed_methods=[\"POST\"],\n",
    "        backoff_factor=1000 # 1000s * 2^0 = 1000s = 16m 40s 기다리고, \n",
    "        # 1000s * 2^1 = 2000s = 33m 20s 기다리고, 1000s * 2^2 = 4000s = 1시간 6분 40초 기다림\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    \n",
    "    return session\n",
    "\n",
    "def fetch_option_data(session: requests.Session, trade_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches option data for a specific trade date.\n",
    "    \"\"\"\n",
    "    payload = PAYLOAD_TEMPLATE.copy()\n",
    "    payload[\"trdDd\"] = trade_date\n",
    "\n",
    "    response = session.post(API_URL, data=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    if \"output\" not in data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(data[\"output\"])\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def save_data_h5(df: pd.DataFrame, filename: str, schema: dict):\n",
    "    # Enforce schema: cast object columns to string\n",
    "    for col, (dtype, _) in schema.items():\n",
    "        if dtype == 'object':\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    # Prepare min_itemsize mapping\n",
    "    min_itemsize = {col: max_len for col, (dtype, max_len) in schema.items() if dtype == 'object'}\n",
    "\n",
    "    # Update min_itemsize if file exists\n",
    "    if Path(filename).exists():\n",
    "        with pd.HDFStore(filename, 'r') as store:\n",
    "            if 'option_data' in store:\n",
    "                storer = store.get_storer('option_data')\n",
    "                for col in min_itemsize:\n",
    "                    if col in storer.min_itemsize:\n",
    "                        min_itemsize[col] = max(min_itemsize[col], storer.min_itemsize[col])\n",
    "\n",
    "    # Append DataFrame\n",
    "    with pd.HDFStore(filename, 'a') as store:\n",
    "        store.append('option_data', df, format='table', data_columns=True, min_itemsize=min_itemsize)\n",
    "\n",
    "\n",
    "def backup_h5_file(source: str, backup_path: Path):\n",
    "    \"\"\"\n",
    "    Copies the HDF5 file to the backup directory with a timestamp.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    backup_path = BACKUP_PATH / f\"krx_option_data_backup_{timestamp}.h5\"\n",
    "    shutil.copy(source, backup_path)\n",
    "    print(f\"Backup created at {backup_path}\")\n",
    "\n",
    "def scrape_krx_option_data(start_date: str, end_date: str) -> None:\n",
    "    \"\"\"\n",
    "    Scrapes KRX option data between start_date and end_date and saves to HDF5.\n",
    "    Implements retry and backup strategies.\n",
    "    \"\"\"\n",
    "    dates = generate_date_range(start_date, end_date)\n",
    "    success_count = 0\n",
    "\n",
    "    session = setup_session()\n",
    "    \n",
    "    for date in tqdm(dates, desc=\"Fetching data\"):\n",
    "        try:\n",
    "            daily_data = fetch_option_data(session, date)\n",
    "            if not daily_data.empty:\n",
    "                daily_data['Trade_Date'] = pd.to_datetime(date, format='%Y%m%d')\n",
    "                save_data_h5(daily_data, H5_FILE, H5_SCHEMA)\n",
    "                success_count += 1\n",
    "                \n",
    "                if success_count % BACKUP_INTERVAL == 0:\n",
    "                    backup_h5_file(H5_FILE, BACKUP_PATH)\n",
    "            \n",
    "            time.sleep(10)  # Delay to mimic human behavior\n",
    "        \n",
    "        \n",
    "        except requests.HTTPError as http_err: # 이미 Retry에서 처리되므로, 별로 필요 없음\n",
    "            print(f\"HTTP error for date {date}: {http_err}\")\n",
    "            time.sleep(100)  # Wait before retrying\n",
    "        except Exception as err:\n",
    "            print(f\"Error for date {date}: {err}\")\n",
    "            time.sleep(100)  # Wait before continuing\n",
    "    \n",
    "    # Final backup after completion\n",
    "    backup_h5_file(H5_FILE, BACKUP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454683f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2024-12-02'\n",
    "end = '2024-12-04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663989d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_date_range(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with requests.Session() as session:\n",
    "#     session.headers.update(HEADERS)\n",
    "    \n",
    "#     payload = PAYLOAD_TEMPLATE.copy()\n",
    "#     payload[\"trdDd\"] = '20241202'\n",
    "\n",
    "#     response = session.post(API_URL, data=payload)\n",
    "#     response.raise_for_status()\n",
    "#     data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd = pd.DataFrame(data['output'])\n",
    "# dd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e70aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707195a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40558f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_krx_option_data(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008805ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
