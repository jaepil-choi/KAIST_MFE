{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 거래소에서 option data 가져와보기\n",
    "\n",
    "- daily snapshot으로 전 행사가, 전 만기를 가져올 수 있어 좋다. 데이터 양이 너무 많다는 것이 문제라면 문제 \n",
    "- 너무 많이 요청했을 때 차단 당한다. \n",
    "    - 차단 안당하게 충분히 sleep 넣어주고, retry도 multiplier 높여주기. \n",
    "    - 카이스트 ip 차단 방지하기 위해 피씨방에 돈 충전하고 크롤링은 parsec으로 원격으로 돌리기. \n",
    "- 차단/중단시 그동안 한거라도 건지기 위해 계속 parquet으로 daily chunk를 저장. \n",
    "\n",
    "- o1 정식 모델을 사용하니 코드 퀄리티가 훨씬 올라갔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Import configurations\n",
    "from krx_config import API_URL, HEADERS, PAYLOAD_TEMPLATE, H5_SCHEMA\n",
    "\n",
    "# Adjust these paths and constants as needed\n",
    "DATA_PATH = Path('data')\n",
    "BACKUP_PATH = Path('backup')\n",
    "OUTPUT_PATH = Path('output')\n",
    "BACKUP_INTERVAL = 10  # Backup after every 10 successful scrapes\n",
    "PARQUET_DIR = DATA_PATH / \"krx_option_parquet\"  # Directory to store parquet files\n",
    "PARQUET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def generate_date_range(start_date: str, end_date: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns a descending list of business days between start_date and end_date in 'YYYYMMDD' format.\n",
    "    \"\"\"\n",
    "    tz = ZoneInfo('Asia/Seoul')\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\").replace(tzinfo=tz)\n",
    "    delta = end - start\n",
    "    date_list = []\n",
    "    for i in range(delta.days + 1):\n",
    "        current_date = end - timedelta(days=i)\n",
    "        if current_date.weekday() < 5:\n",
    "            date_list.append(current_date.strftime(\"%Y%m%d\"))\n",
    "    return date_list\n",
    "\n",
    "def setup_session() -> requests.Session:\n",
    "    session = requests.Session()\n",
    "    session.headers.update(HEADERS)\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[400, 429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"POST\"],\n",
    "        backoff_factor=1000\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "def fetch_option_data(session: requests.Session, trade_date: str) -> pd.DataFrame:\n",
    "    payload = PAYLOAD_TEMPLATE.copy()\n",
    "    payload[\"trdDd\"] = trade_date\n",
    "    response = session.post(API_URL, data=payload)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    if \"output\" not in data:\n",
    "        return pd.DataFrame()\n",
    "    return pd.DataFrame(data[\"output\"])\n",
    "\n",
    "def save_data_parquet(df: pd.DataFrame, trade_date: str):\n",
    "    # Convert data types if needed; for parquet, this is often optional, but let's ensure strings:\n",
    "    for col, (dtype, _) in H5_SCHEMA.items():\n",
    "        if col in df.columns and dtype == 'object':\n",
    "            df[col] = df[col].astype(str)\n",
    "    # Save each day's data as a separate parquet file\n",
    "    file_path = PARQUET_DIR / f\"option_data_{trade_date}.parquet\"\n",
    "    df.to_parquet(file_path, index=False)\n",
    "\n",
    "def backup_parquet_dir(source_dir: Path, backup_path: Path):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    backup_dir = backup_path / f\"krx_option_parquet_backup_{timestamp}\"\n",
    "    shutil.copytree(source_dir, backup_dir)\n",
    "    print(f\"Backup created at {backup_dir}\")\n",
    "\n",
    "def scrape_krx_option_data(start_date: str, end_date: str) -> None:\n",
    "    dates = generate_date_range(start_date, end_date)\n",
    "    success_count = 0\n",
    "    session = setup_session()\n",
    "\n",
    "    for date in tqdm(dates, desc=\"Fetching data\"):\n",
    "        try:\n",
    "            daily_data = fetch_option_data(session, date)\n",
    "            if not daily_data.empty:\n",
    "                daily_data['Trade_Date'] = pd.to_datetime(date, format='%Y%m%d')\n",
    "                save_data_parquet(daily_data, date)\n",
    "                success_count += 1\n",
    "                if success_count % BACKUP_INTERVAL == 0:\n",
    "                    backup_parquet_dir(PARQUET_DIR, BACKUP_PATH)\n",
    "            \n",
    "            time.sleep(10)\n",
    "        \n",
    "        except requests.HTTPError as http_err:\n",
    "            print(f\"HTTP error for date {date}: {http_err}\")\n",
    "            time.sleep(100)\n",
    "        except Exception as err:\n",
    "            print(f\"Error for date {date}: {err}\")\n",
    "            time.sleep(100)\n",
    "\n",
    "    # Final backup after completion\n",
    "    backup_parquet_dir(PARQUET_DIR, BACKUP_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching data: 100%|██████████| 3/3 [00:45<00:00, 15.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup created at backup\\krx_option_parquet_backup_20241207131629\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "start = '2024-12-02'\n",
    "end = '2024-12-04'\n",
    "scrape_krx_option_data(start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame memory usage: 11.45 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Schema and type info from your snippet\n",
    "column_to_name = {\n",
    "    'ISU_CD': 'option_sid(full)',\n",
    "    'ISU_SRT_CD': 'option_sid(short)',\n",
    "    'ISU_NM': 'option_name',\n",
    "    'TDD_CLSPRC': 'close_price',\n",
    "    'FLUC_TP_CD': 'up_or_down',\n",
    "    'CMPPREVDD_PRC': 'price_change',\n",
    "    'TDD_OPNPRC': 'open_price',\n",
    "    'TDD_HGPRC': 'high_price',\n",
    "    'TDD_LWPRC': 'low_price',\n",
    "    'IMP_VOLT': 'im_vol',\n",
    "    'NXTDD_BAS_PRC': 'next_day_base_price',\n",
    "    'ACC_TRDVOL': 'trade_volume',\n",
    "    'ACC_TRDVAL': 'trade_value',\n",
    "    'ACC_OPNINT_QTY': 'open_interest_quantity',\n",
    "    'SECUGRP_ID': 'security_type',\n",
    "    'Trade_Date': 'trade_date',\n",
    "    'Uly_Code': 'underlying_code',\n",
    "}\n",
    "\n",
    "float_cols = [\n",
    "    'close_price', 'price_change', 'open_price', 'high_price', 'low_price',\n",
    "    'im_vol', 'next_day_base_price', 'trade_volume', 'trade_value',\n",
    "    'open_interest_quantity', 'expiration', 'up_or_down'\n",
    "]\n",
    "\n",
    "DATA_PATH = Path('data')\n",
    "PARQUET_DIR = DATA_PATH / \"krx_option_parquet\"\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "for file in PARQUET_DIR.glob(\"*.parquet\"):\n",
    "    daily_df = pd.read_parquet(file)\n",
    "    # Rename columns\n",
    "    daily_df = daily_df.rename(columns=column_to_name)\n",
    "\n",
    "    # Convert columns to numeric\n",
    "    for float_col in float_cols:\n",
    "        if float_col in daily_df.columns:\n",
    "            daily_df[float_col] = daily_df[float_col].str.replace('-', '', regex=False)\n",
    "            daily_df[float_col] = daily_df[float_col].str.replace(',', '', regex=False)\n",
    "            daily_df[float_col] = pd.to_numeric(daily_df[float_col], errors='raise')\n",
    "\n",
    "    # Convert trade_date to datetime\n",
    "    if 'trade_date' in daily_df.columns:\n",
    "        daily_df['trade_date'] = pd.to_datetime(daily_df['trade_date'])\n",
    "\n",
    "    # Concatenate to the main DataFrame\n",
    "    df_all = pd.concat([df_all, daily_df], ignore_index=True)\n",
    "\n",
    "# print(df_all.head())\n",
    "print(\"DataFrame memory usage: {:.2f} MB\".format(\n",
    "    df_all.memory_usage(deep=True).sum() / (1024**2)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27916 entries, 0 to 27915\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   option_sid(full)        27916 non-null  object        \n",
      " 1   option_sid(short)       27916 non-null  object        \n",
      " 2   option_name             27916 non-null  object        \n",
      " 3   close_price             2301 non-null   float64       \n",
      " 4   up_or_down              27916 non-null  int64         \n",
      " 5   price_change            2301 non-null   float64       \n",
      " 6   open_price              2301 non-null   float64       \n",
      " 7   high_price              2301 non-null   float64       \n",
      " 8   low_price               2301 non-null   float64       \n",
      " 9   im_vol                  27916 non-null  float64       \n",
      " 10  next_day_base_price     27916 non-null  float64       \n",
      " 11  trade_volume            27916 non-null  int64         \n",
      " 12  trade_value             27916 non-null  int64         \n",
      " 13  open_interest_quantity  27916 non-null  int64         \n",
      " 14  security_type           27916 non-null  object        \n",
      " 15  trade_date              27916 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(7), int64(4), object(4)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strike price 등의 정보를 이름에서 파싱 \n",
    "\n",
    "import re\n",
    "\n",
    "def parse_option_name(option_name):\n",
    "    pattern = r\"(?P<underlying>[\\w가-힣]+)\\s+(?P<call_or_put>[CP])\\s+(?P<expiration>\\d{6})\\s+(?P<strike>[\\d,]+)\\(\\s*(?P<multiplier>\\d+)\\)\"\n",
    "\n",
    "    # Match the pattern\n",
    "    match = re.match(pattern, option_name)\n",
    "\n",
    "    # Extract data if a match is found\n",
    "    if match:\n",
    "        data = {\n",
    "            \"underlying\": match.group(\"underlying\"),\n",
    "            \"call_or_put\": match.group(\"call_or_put\"),\n",
    "            \"expiration\": match.group(\"expiration\"),\n",
    "            \"strike\": float(match.group(\"strike\").replace(\",\", \"\")),\n",
    "            \"multiplier\": int(match.group(\"multiplier\")),\n",
    "        }\n",
    "\n",
    "        return data\n",
    "        \n",
    "    else:\n",
    "        data = {\n",
    "            \"underlying\": None,\n",
    "            \"call_or_put\": None,\n",
    "            \"expiration\": None,\n",
    "            \"strike\": None,\n",
    "            \"multiplier\": None,\n",
    "        }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = df_all['option_name'].apply(parse_option_name)\n",
    "parsed_df = pd.DataFrame(parsed_data.tolist())\n",
    "\n",
    "# Combine the parsed data with the original DataFrame\n",
    "\n",
    "df_final = pd.concat([df_all, parsed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
