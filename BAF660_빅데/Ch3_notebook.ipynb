{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0e63c0",
   "metadata": {},
   "source": [
    "Ch3\n",
    "\n",
    "April 9, 2025\n",
    "\n",
    "1 Lending Club Data\n",
    "\n",
    "• Lending Club 데이터\n",
    "– 2007~2017 3분기의 기간 동안의 대출 데이터 (Kaggle 제공, https://www.kaggle.com/wendykan/lending-club-loan-data)\n",
    "– 원 자료는 88만개 이상의 사례의 150개 특성변수에 대한 정보를 담고 있음.\n",
    "– 10만 건을 random sampling한 자료에 대해 데이터 정제, 특성 선택 및 변환 등의 전처리를 적용한 데이터를 이용하여 분석."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad43b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.read_csv('/content/drive/MyDrive/2025 Spring/빅데이터와 금융자료분석/LoanData.csv')\n",
    "datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetX, datasetY = datasets.drop('charged_off', axis=1), datasets['charged_off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(datasetX, datasetY, test_size=0.2, random_state=123)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=1/8, random_state=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276568c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70ad78",
   "metadata": {},
   "source": [
    "2 XGBoost\n",
    "\n",
    "• xgboost.XGBClassifier(분류)와 xgboost.XGBRegressor(회귀) 클래스\n",
    "– Implementation of the scikit-learn API for XGBoost regressor/classifier\n",
    "\n",
    "XGBoost 파라미터\n",
    "\n",
    "• General 파라미터\n",
    "– booster\n",
    "  * ‘gbtree’(default), ‘gblinear’, ‘dart’ 중 하나를 선택.\n",
    "– verbosity\n",
    "  * 메세지 출력 범위 설정, 0(silent), 1(warning), 2(info), 3(debug)\n",
    "– n_jobs\n",
    "  * xgboost를 실행하는 데 사용되는 병렬 thread의 수.\n",
    "  * default는 모두 사용하는 것。\n",
    "\n",
    "• Booster 파라미터 (‘gbtree’ 기준)\n",
    "– n_estimators\n",
    "  * 몇 개의 estimator를 포함하는지를 입력.\n",
    "  * default는 100。\n",
    "\n",
    "– learning_rate\n",
    "  * 학습률。 default는 0.3이고 0~1의 사이로 입력。\n",
    "  * 과적합을 방지하기 위해 각 estimator의 가중치를 줄여주는 역할을 함。\n",
    "  * 작을수록 모델이 견고해지고 과적합 방지에 좋지만、 더 많은 estimators가 요구되며 학습시간은 길어짐。\n",
    "\n",
    "– min_child_weight\n",
    "  * 트리 노드 분할 시 자식노드에 속한 자료들의 weight의 합에 대한 최소값。\n",
    "\n",
    "– gamma\n",
    "  * pruning 관련 하이퍼파라미터\n",
    "  * 양의 실수 값으로 설정。 default는 0임。\n",
    "  * 클 수록 과적합을 방지하나、 너무 큰 경우 언더피팅이 될 수 있음。\n",
    "\n",
    "– reg_lambda\n",
    "  * L2 규제 하이퍼파라미터\n",
    "  * 커질수록 보수적인 모델이 되어 과적합을 방지하나、 너무 큰 경우 언더피팅이 될 수 있음。\n",
    "\n",
    "– reg_alpha\n",
    "  * L1 규제 하이퍼파라미터\n",
    "  * 커질수록 보수적인 모델이 되어 과적합을 방지하나、 너무 큰 경우 언더피팅이 될 수 있음。\n",
    "  * 특성변수가 sparse하거나 매우 많을 때 적용 권장。\n",
    "\n",
    "– max_depth\n",
    "  * estimator로 사용되는 각 트리의 최대깊이。 default는 6임。\n",
    "  * 최대 깊이의 트리는 -1로 설정。\n",
    "  * 데이터의 복잡도에 따라 적정한 깊이가 설정되어야 함।\n",
    "  * 너무 작으면 언더피팅이 될 수 있고、 너무 크면 오버피팅의 가능성이 높아지며 학습시간이 길어짐。\n",
    "\n",
    "– subsample\n",
    "  * 각 트리 단위로 적용되는 Row sampling 비율로 과적합을 방지하고 학습시간을 줄여줌。\n",
    "  * 0~1 사이의 값을 입력。 default는 1임。\n",
    "\n",
    "– colsample_bytree\n",
    "  * 각 트리 단위로 적용되는 Column sampling 비율로 과적합을 방지하고 학습시간을 줄여줌。\n",
    "  * 0~1 사이의 값을 입력。 default는 1임。\n",
    "\n",
    "– tree_method\n",
    "  * ‘auto’(default)、‘exact’、‘approx’、‘hist’、‘gpu_hist’ 중 하나를 선택。\n",
    "  * ‘auto’는 데이터의 크기가 작은 경우에는 ’exact’、 큰 경우에는 ’approx’ 를 적용하는 것임。\n",
    "\n",
    "– sketch_eps\n",
    "  * tree_method가 ’approx’인 경우에만 적용됨。\n",
    "  * 버킷의 수는 1/sketch_eps로 결정되며、 default는 0.03임。\n",
    "\n",
    "– scale_pos_weight\n",
    "  * 범주의 비중이 불균형인 이진 분류 문제에서 cost-sensitive training을 하도록 함。\n",
    "  * sum(negative instances) / sum(positive instances) 로 입력。\n",
    "\n",
    "• Learning Task 파라미터\n",
    "\n",
    "– objective\n",
    "  * 손실함수 지정。 이를 최소로 하도록 학습함。\n",
    "  * 자주 활용되는 손실함수\n",
    "    · reg:squarederror : 회귀용。 오차제곱 손실。\n",
    "    · reg:squaredlogerror : 회귀용。 오차로그제곱 손실。\n",
    "    · binary:logistic : 이진 분류용。 예측 확률 반환。\n",
    "    · multi:softmax : 다중 분류용。 예측 클래스 반환。\n",
    "    · multi:softprob : softmax와 동일한데、 예측 확률 반환。\n",
    "\n",
    "– base_score\n",
    "  * 초기편향치로、 defaul t는 0.5임。\n",
    "\n",
    "– eval_metric\n",
    "  * 평가지표 지정。 각 스텝마다 완성된 모델을 이 지표를 통해 평가함。\n",
    "  * 자주 활용되는 평가지표\n",
    "    · rmse : root mean square error (회귀의 default)\n",
    "    · mae : mean absolute error\n",
    "    · logloss : negative log-likelihood\n",
    "    · mlogloss : multiclass logloss\n",
    "    · error : binary classification error rate 로 임계치는 0.5 기준 (분류의 default) (error@t : 임계치 t 를 적용한 error rate)\n",
    "    · merror : multiclass classification error rate\n",
    "    · auc : area under the curve\n",
    "\n",
    "– early_stopping_rounds\n",
    "  * eval_metric의 지표가 early_stopping_rounds 횟수 동안 개선되지 않으면、 n_estimators 에 도달하기 전에 멈추도록 함。\n",
    "  * 양의 정수값으로 입력。 default는 0。\n",
    "  * fit() 메서드에서 검증용 데이터를 eval_set 에 지정해 주어야 함。\n",
    "  * 훈련이 끝난 인스턴스의 best_ntree_limit 속성을 이용하여 최적의 tree 갯수를 확인할 수 있으며、 predict() 메서드로 예측 시에는 ntree_limit=best_ntree_limit 가 적용됨。\n",
    "\n",
    "XGBoost 모델 학습과 예측\n",
    "\n",
    "• 주요 메서드\n",
    "– fit(X_train, y_train) 메서드로 모델을 학습\n",
    "  * eval_set : [(X_eval, y_eval)] 형식으로 검증데이터 지정할 수 있음。\n",
    "\n",
    "– predict(X_test) 메서드로 학습된 모델을 이용한 예측\n",
    "  * ntree_limit : default는 0(모든 tree를 사용) 인데、 early_stopping 이 적용된 경우 best_ntree_limit 이 적용됨。\n",
    "\n",
    "– evals_result() 메서드로 검증데이터에 대한 평가 결과를 확인。 단、 fit() 메서드에서 eval_set 에 검증용 데이터가 지정되어 있어야 함。\n",
    "\n",
    "• 주요 속성\n",
    "– feature_importances_ : 각 특성변수 별 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(booster='gbtree', objective='binary:logistic',\n",
    "                      learning_rate=0.1,\n",
    "                      scale_pos_weight=float(Y_train.value_counts()[0]) / Y_train.value_counts()[1],\n",
    "                      verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a27995",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 500],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'min_child_weight': [0, 0.1, 0.3, 0.5],\n",
    "    'gamma': [0, 0.1, 1, 5],\n",
    "    'colsample_bytree': [0.6, 0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "grid_xgb = RandomizedSearchCV(model,\n",
    "                              param_distributions=params,\n",
    "                              n_iter=25,\n",
    "                              cv=3,\n",
    "                              scoring='accuracy',\n",
    "                              refit=True)\n",
    "grid_xgb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3420f5d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print(grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ca07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridresult = pd.DataFrame(grid_xgb.cv_results_).iloc[:, [4,5,6,7,8,13,14,15]]\n",
    "gridresult.sort_values(['rank_test_score'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalmodel = XGBClassifier(booster='gbtree', objective='binary:logistic',\n",
    "                           verbosity=0,\n",
    "                           colsample_bytree=0.6, gamma=0.1, max_depth=9,\n",
    "                           min_child_weight=0.1,\n",
    "                           n_estimators=10000, learning_rate=0.01,\n",
    "                           scale_pos_weight=float(Y_train.value_counts()[0]) / Y_train.value_counts()[1],\n",
    "                           eval_metric='logloss',\n",
    "                           early_stopping_rounds=1000)\n",
    "finalmodel.fit(X_train, Y_train,\n",
    "               eval_set=[(X_train, Y_train), (X_val, Y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3737c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = finalmodel.evals_result()\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['validation_0'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['validation_0']['logloss'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result['validation_0']['logloss'], label='training_logloss')\n",
    "plt.plot(result['validation_1']['logloss'], label='validation_logloss')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('log loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb76888",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_values = pd.Series(finalmodel.feature_importances_, index=X_train.columns)\n",
    "imp_values = imp_values.sort_values(ascending=False)\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=imp_values, y=imp_values.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f844b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finalmodel.predict(X_train.iloc[0:1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ae586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finalmodel.predict_proba(X_train.iloc[0:1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = finalmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e87421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "idx = 12\n",
    "print(X_train.iloc[idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83107cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88715b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finalmodel.predict(X_train.iloc[idx:(idx+1), :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finalmodel.predict_proba(X_train.iloc[idx:(idx+1), :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(finalmodel)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc9226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[idx, :], X_train.iloc[idx, :], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
