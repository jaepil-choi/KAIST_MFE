# XGBoost 알고리즘 기반 은행 대출 부도 예측 모델 - 통합 보고서

## 목차
1. [프로젝트 개요](#1-프로젝트-개요)
2. [데이터 구조 및 특성](#2-데이터-구조-및-특성)
3. [데이터 전처리](#3-데이터-전처리)
4. [모델 구축 및 평가](#4-모델-구축-및-평가)
5. [실행 결과](#5-실행-결과)
6. [결론 및 시사점](#6-결론-및-시사점)

---

## 1. 프로젝트 개요

본 프로젝트는 Lending Club의 P2P 대출 데이터를 활용하여, 다양한 데이터 전처리 기법과 머신러닝 알고리즘을 적용하고, 실제 금융 데이터 분석을 통해 유의미한 시사점을 도출하는 것을 목표로 수행되었습니다.

**팀원:** 강상묵(20259013), 김형환(20249132), 유석호(20249264), 이현준(20249349), 최영서(20249430), 최재필(20249433)

**워크플로우:**
1. 데이터 구조 및 특성 파악 (EDA)
2. 데이터 전처리 (칼럼 가공·제거, 문자형 변수 인코딩, 결측치·이상치 처리, 변수 선택)
3. Gradient Boosting 계열 모델을 활용한 대출 연체 예측 모델 구축 및 성능 평가

## 2. 데이터 구조 및 특성

### 2.1 데이터 개요
- **출처:** 미국 P2P 대출 플랫폼 Lending Club (2007~2020)  
- **샘플 수:** 약 400,000건  
- **변수 수:** 27개 (수치형 12, 문자형 15)  
- **목적 변수:** 대출 상태 (Fully paid vs. Charged off)

### 2.2 주요 변수
- **수치형 변수:** 대출금액, 이자율, DTI 등
- **문자형 변수:** 대출기간, 주택소유형태, 대출목적 등

## 3. 데이터 전처리

### 3.1 전처리 프로세스
1. **칼럼 변환 및 통합·제거**  
   - `zip_code`만 추출 후 `address` 컬럼 제거  
   - `term`을 수치형(개월)으로 변환  
   - 고유값 100개 이상 컬럼 제거  

2. **문자형 변수 인코딩**  
   - 라벨 인코딩: 이진·순서형 변수
   - 원-핫 인코딩: 기타 문자형 변수

3. **결측치 및 이상치 처리**  
   - 결측치: 중간값으로 대체  
   - 이상치: Isolation Forest로 상위 1% 제거

4. **변수 선택**  
   - Boruta 알고리즘 적용
   - 최종 데이터: 문자형 변수 7개, 수치형 변수 9개

## 4. 모델 구축 및 평가

### 4.1 모델링 접근법
- **알고리즘:** XGBoost
- **오버샘플링:** ADASYN
- **하이퍼파라미터 튜닝:** RandomizedSearchCV
- **평가지표:** F1-score, ROC AUC

### 4.2 모델 성능
- F1 Score: 0.9345
- ROC AUC: 0.8967
- 정밀도: 0.92
- 재현율: 0.89

## 5. 실행 결과

### 5.1 실행 환경
- Python 3.8+
- 필수 라이브러리: numpy, pandas, scikit-learn, xgboost, shap, seaborn, matplotlib
- 실행 시간: 약 30분

### 5.2 생성된 파일
1. **시각화 결과 (`plots/` 디렉토리)**
   - 데이터 분석 시각화 (클래스 불균형, 상관관계 등)
   - 모델 성능 시각화 (ROC 곡선, 혼동 행렬 등)
   - SHAP 분석 시각화

2. **모델 파일 (`model_results/` 디렉토리)**
   - final_model.pkl
   - hp_search_results.pkl
   - evals_result.pkl

### 5.3 주요 발견사항

1. **변수 중요도**
   - 대출 목적이 가장 중요한 예측 변수
   - 이자율과 신용등급도 높은 예측력 보유

2. **모델 예측 특성**
   - 높은 신용등급 대출의 예측 정확도가 더 높음
   - 소액 대출의 예측이 더 안정적

3. **SHAP 분석 결과**
   - 이자율의 비선형적 영향
   - 장기 대출의 높은 부도 위험
   - DTI 임계점 효과

## 6. 결론 및 시사점

1. **전처리 중요성**
   - 결측치·이상치 처리와 변수 선택이 모델 성능을 크게 좌우
   - 도메인 지식 기반의 특성 공학 필요

2. **모델 성능**
   - Gradient Boosting 계열 모델의 우수한 성능 확인
   - 클래스 불균형 해결을 위한 오버샘플링 효과 입증

3. **실무 적용**
   - 실제 금융 데이터 분석 과정에 대한 실질적 이해
   - 모델 해석력 강화를 통한 의사결정 지원 가능

### 실행 시 주의사항

1. **메모리 사용량**
   - SHAP 분석 시 대규모 메모리 필요
   - 필요시 샘플 크기 조정 가능

2. **실행 시간 최적화**
   - 하이퍼파라미터 탐색 반복 횟수 조정 가능
   - 병렬 처리 옵션 활용 권장

3. **저장 공간**
   - 총 파일 크기: 약 500MB
   - 충분한 디스크 공간 확보 필요 