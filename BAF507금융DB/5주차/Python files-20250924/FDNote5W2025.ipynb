{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eabcc52-d84c-4d43-b147-e3bab93d67f9",
   "metadata": {},
   "source": [
    "# FDNote5W.ipynb\n",
    "\n",
    "Prepared by Inmoo Lee for the Financial Databases class at KAIST\n",
    "\n",
    "inmool@kaist.ac.kr\n",
    "\n",
    "For portfolio return calculations using SQL\n",
    "\n",
    "Input files used\n",
    "\n",
    "    - 2020SP500Constituents_2025_Short.xlsx\n",
    "    - return_data.ft\n",
    "    - note4data.xlsx\n",
    "    - fbhrs.ft\n",
    "    - Note3w_RHistory2025_Short.xlsx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40895526-ec73-4588-8f66-c403fed60daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #import a package called os\n",
    "\n",
    "os.getcwd()  #get the current working directory\n",
    "path='D:\\\\####'#Change this to your directory\n",
    "os.chdir(path) # change the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce498ee1-d1f4-457e-8952-e94424d00531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341c751-bf25-40bf-bbf4-d1201caa6a6c",
   "metadata": {},
   "source": [
    "# Calculate portfolio returns using SQL\n",
    "\n",
    "Equally-weighted vs. value-weighted returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39fc1f-4bbf-4fa0-9f04-0effc9065398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the equally-weighted average return in each month\n",
    "from pandasql import sqldf\n",
    "def pysqldf(q):\n",
    " return sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "df=pd.read_feather('./return_data.ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed6479-5dfb-4b21-979d-b1eab08bcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "## As discussed before, we can find the the month end any # of months before/after\n",
    "### you have to convert the floating 64 format Date to integer and then to string format\n",
    "### to use pd_to_datetime\n",
    "\n",
    "df.loc[:,'date1']=pd.to_datetime(round(df.loc[:,'Date']).astype(int).astype(str),format='%Y%m%d')+MonthEnd(0)\n",
    "###find the date 12 months after (+12) and before (-12) the current date\n",
    "df.loc[:,'fmonth12']=df.loc[:,'date1']+MonthEnd(+12)\n",
    "df.loc[:,'bmonth12']=df.loc[:,'date1']+MonthEnd(-12)\n",
    "print(df[['date1','fmonth12','bmonth12']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51d466-f7f0-47d0-820e-08fd452b2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "###find yyyymm to be used as an time indicator (year+month)\n",
    "### since date1 is a datetime variable, dt.year and dt.month\n",
    "### can be used to get year and month from a date.\n",
    "df.loc[:,'yyyymm']=df.loc[:,'date1'].dt.year*100+df.date1.dt.month\n",
    "print(df[['yyyymm']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13808e8-db0f-4cab-a4f3-cac713cfa27d",
   "metadata": {},
   "source": [
    "## Portfolio return calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4070e5-79ec-46db-9381-d0e27cad033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import the market cap information \n",
    "marketc=pd.read_excel('./note4data.xlsx', sheet_name=\"marketcap\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e4d597-eb96-40bd-86b3-ee2933378108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "# convert \"Date\" to a datetime variable recognized in Pandas and call it \"rdate\"\n",
    "# make a time indicator variable (yyyymm), which is same the one as used above\n",
    "marketc['rdate']=pd.to_datetime(marketc['Date'].astype(int).astype(str),format='%Y%m%d')+MonthEnd(0)\n",
    "marketc['yyyymm']=marketc.rdate.dt.year*100+marketc.rdate.dt.month\n",
    "print(marketc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f58e49-916d-46be-8b73-e6a785e413b7",
   "metadata": {},
   "source": [
    "#### Find lagged market cap values and ids\n",
    "Here, by using *groupby(['ID'])*, lagged values are *correctly* identified for each id\n",
    "\n",
    "It is also important to note that the file should be **sorted by (ID and Date)** before lagged values are identified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9a2ce-7ed9-48d6-b10a-a755c92275c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(marketc.columns)\n",
    "# Calculate the market capitalization by multiplying Price and Numsh\n",
    "marketc['marketcap']=marketc.Price * marketc.Numsh\n",
    "\n",
    "# Sort the marketcap data by ID and Date\n",
    "# This is important to use .sort_values() before using .shift()\n",
    "# After sorting, reset the index to avoid confusion\n",
    "marketcap=marketc.sort_values(['ID','Date'],ascending=True).reset_index(drop=True)\n",
    "# Check whether the sorting is correct\n",
    "print(marketcap.head())\n",
    "##Here, it is important to use .shirt(1) with groupby(['ID']) \n",
    "### to correctly get the lagged market cap for each ID\n",
    "### Otherwise, it may use the other ID's market cap as its lagged value\n",
    "\n",
    "## shift(1) means the previous row in the group\n",
    "## If you want to use the next row, use shift(-1)\n",
    "marketcap['lmc']=marketcap.groupby(['ID'])['marketcap'].shift(1)#lagged marketcap\n",
    "marketcap['lid']=marketcap.groupby(['ID'])['ID'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e5e30-73c6-458f-990e-e39e54060c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the lagged market cap is correct\n",
    "print(marketcap[['ID','Date','marketcap','lmc','lid']].head())\n",
    "print(marketcap.loc[160:180,['ID','Date','marketcap','lmc','lid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read fbhrs.ft, which we created last week.\n",
    "fbhrs=pd.read_feather('./fbhrs.ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae6a2f-b0bb-4933-ac4b-e786e810fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*add market cap information to bhr file*/\n",
    "# Use the SQL to combine two dataframes.\n",
    "# Note that two dataframes are merged by matching ids and yyyymm values\n",
    "query='''select a.*,b.marketcap,b.lmc,b.rdate\n",
    "            from fbhrs as a\n",
    "            left join marketcap as b\n",
    "            where a.id = b.ID and a.yyyymm = b.yyyymm\n",
    "            order by a.id, a.yyyymm'''\n",
    "#Run the query and store the result in bhrmc\n",
    "bhrmc=pysqldf(query)\n",
    "\n",
    "print(bhrmc.head())\n",
    "print(bhrmc.describe())\n",
    "print(bhrmc['bhr1y'])\n",
    "print(bhrmc['bhr1y'].tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e66da6-1e3c-4d8f-9088-d05d9bac04e8",
   "metadata": {},
   "source": [
    "## Value-weighted returns\n",
    "\n",
    "$R_{vw}=\\sum_{i=1}^{n} w_i \\times R_i$ where $w_i= \\frac{MC_i}{\\sum_{i=1}^{n} MC_i} $\n",
    "\n",
    "Therefore, $R_{vw}=\\sum_{i=1}^{n} \\frac{MC_i}{\\sum_{i=1}^{n} MC_i} \\times R_i = \\frac{\\sum_{i=1}^{n} MC_i \\times R_i}{\\sum_{i=1}^{n} MC_i}$\n",
    "\n",
    "One thing you have to be aware of is the fact that the market cap used here should be the market cap at the **beginning of the month (lmc)**, not at the end of the month.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b642f-7429-42b2-bc98-25ab0077aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*calculate equally-weighted and value-weighted returns of three stocks */\n",
    "# Note that sum are calculated in each group specified in \"group by\"(i.e., in each month (yyyymm)).\n",
    "# In other words, equally- and value-weighted returns are calculated in each yyyymm\n",
    "\n",
    "query='''select a.yyyymm, sum(a.bhr1y)/count(a.bhr1y) as ewbhr1y,\n",
    "                sum(a.bhr1y * a.lmc) / sum(a.lmc) as vwbhr1y, \n",
    "                count(a.bhr1y) as numstock\n",
    "            from bhrmc as a\n",
    "            group by a.yyyymm\n",
    "            order by a.yyyymm'''\n",
    "\n",
    "# Run the query and store the result in portret\n",
    "portret=pysqldf(query)\n",
    "\n",
    "# Check the first 20 rows and the last few rows of portret\n",
    "print(portret.head(20))\n",
    "print(portret.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba8a2d-82e1-4ce9-a927-0d0ca872002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*Compare average equally- and value-weighted returns*/\n",
    "# The following calcualte simple averages of monthly equally- and value-\n",
    "# weighted returns calculated above across all year/month\n",
    "\n",
    "query='''select avg(a.ewbhr1y) as avgew, avg(a.vwbhr1y) as avgvw\n",
    "            from portret as a'''\n",
    "summary=pysqldf(query)\n",
    "print('Average using SQL   :\\n', summary.head())\n",
    "print('Average using mean   :\\n', portret[['ewbhr1y','vwbhr1y']].mean())\n",
    "print(portret.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91fc00e-2f25-48e4-8ca1-479aaa28b160",
   "metadata": {},
   "source": [
    "## Form portfolios based on market cap\n",
    "\n",
    "Check which company has larger cap during the sample period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d1dc0-e2fb-4e84-b5d4-1b699c6b5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the average lagged market cap for each id\n",
    "# and call it avgmarketcap\n",
    "# Note that avgmarketcap is the average of lagged market cap (lmc) for each ID acorr time\n",
    "\n",
    "query='''select b.id, avg(b.lmc) as avgmarketcap \n",
    "            from marketcap as b group by b.id'''\n",
    "\n",
    "summc=pysqldf(query)\n",
    "print('Average calculated using sql: \\n',summc)\n",
    "print('Average calculated using mean()/groupby(): \\n',marketcap.groupby('ID').lmc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76824770-05b7-4dcb-b93d-6150bbc11f8e",
   "metadata": {},
   "source": [
    "#### Find out the size group using only the market caps in Jan. 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e418a6-a61c-46ce-a4f0-935505daa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign firms into a size portfolio based on the market cap on 20010131\n",
    "\n",
    "# First, find out the median of the market cap in Jan. 2001 and call it med\n",
    "bhrmc['med']=np.median(bhrmc[bhrmc['yyyymm']==200101]['marketcap'])# calcualte the median market cap in Jan 2001\n",
    "\n",
    "# Check the median value\n",
    "print(bhrmc.med.describe())\n",
    "print(bhrmc.head(200))\n",
    "#check the median market cap in Jan 2001 to see whether med is correct\n",
    "print(bhrmc.loc[bhrmc.yyyymm==200101,['marketcap']].describe())\n",
    "\n",
    "# Check the median market cap and market cap of each firm in Jan 2001\n",
    "print(bhrmc[bhrmc.yyyymm==200101][['med','marketcap','id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e05d1-b76b-40b1-a69a-2494d1a6540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign firms into a size portfolio based on the market cap on 20010131\n",
    "\n",
    "# Use SQL for the portfolio assignment\n",
    "# find the list of ids available in Jan. 2001 and add a size indicator (isize)\n",
    "# based on the median market cap in Jan. 2001 found above (\"med\") (1=large, 2=small)\n",
    "\n",
    "# Note that \"case when\" is used to assign a value based on a condition\n",
    "# If the condition is true, it returns 1, otherwise it returns 2\n",
    "\n",
    "query='''select a.id, \n",
    "                case when a.marketcap >= a.med then 1 else 2 end as isize\n",
    "            from bhrmc as a\n",
    "            where a.yyyymm = 200101\n",
    "            order by a.id'''\n",
    "\n",
    "# Run the query and store the result in isize\n",
    "isize=pysqldf(query)\n",
    "\n",
    "# Check the columns and the first few rows of isize\n",
    "print(isize.columns)\n",
    "print(isize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd92c4-6e5c-4eb3-8e2b-1a099bb3b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the above result with the bhrmc dataframe by matching ids\n",
    "# (adding isize to bhrmc file)\n",
    "\n",
    "query='''select a.*,b.isize\n",
    "            from bhrmc as a\n",
    "            left join isize as b\n",
    "            on a.id = b.id\n",
    "            order by a.id, a.yyyymm'''\n",
    "bhrmc2=pysqldf(query)\n",
    "\n",
    "# Confirm that isize is added to bhrmc2\n",
    "print(bhrmc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70992686-5179-4097-bb1f-57209502e45f",
   "metadata": {},
   "source": [
    "### Calculate summary statistics for each isize group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SQL to summarize the average, maximum, minimum, and count of bhr1y\n",
    "# grouped by isize (size portfolio)\n",
    "\n",
    "query='''select a.isize,avg(a.bhr1y) as avg, max(a.bhr1y) as max, min(a.bhr1y) as min,\n",
    "                count(a.bhr1y) as num\n",
    "            from bhrmc2 as a\n",
    "            group by a.isize'''\n",
    "summary=pysqldf(query)\n",
    "print(summary)\n",
    "\n",
    "#Alternativley, you can use the following code to summarize the average, maximum, minimum, and count of bhr1y\n",
    "# grouped by isize (size portfolio)\n",
    "print(bhrmc2.groupby('isize')['bhr1y'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2f35b-f086-4a3a-8409-792039f8c0ac",
   "metadata": {},
   "source": [
    "# Calendar-time portfolio formation and return calculation\n",
    "\n",
    "### Calendar time portfolio is a portfolio formed in each month\n",
    "#### In each month, the portfolio is composed of firms that had an event within the past 24 mont\n",
    "\n",
    "A firm is included **only once** even if it had multiple events within the past 24 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc4162-1669-4b82-b094-a744fe8ca727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data\n",
    "\n",
    "events=pd.read_excel('./note4data.xlsx', sheet_name=\"Events\", header=0)\n",
    "print(events.dtypes)\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8a5bc-0899-4660-9256-838f3e0e9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/*combine the event data with the return data*/\n",
    "# Match by ids only\n",
    "\n",
    "query='''select a.*,b.rdate,b.return,b.lmc,b.marketcap\n",
    "            from events as a\n",
    "            left join marketcap as b \n",
    "            on a.id=b.id\n",
    "            order by a.id, a.date,b.date'''\n",
    "\n",
    "eventret=pysqldf(query)\n",
    "\n",
    "print(eventret.head())\n",
    "# Check the number of rows and columns for eventret and two input dataframes\n",
    "print(\"Number of rows and columns in eventret:\", eventret.shape)\n",
    "print(\"Number of rows and columns in events:\", events.shape)\n",
    "print(\"Number of rows and columns in marketcap:\", marketcap.shape)\n",
    "\n",
    "#This is not a Cartesian product, but a join\n",
    "# Therefore, the number of rows in eventret is NOT the product of\n",
    "# the number of rows in events and marketcap\n",
    "\n",
    "print(events.shape[0]*marketcap.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d33a6c-f885-46f9-8cd3-da75b25d19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the date format of Date in eventret\n",
    "## to a datetime variable and call it \"edate\" (event date)\n",
    "\n",
    "## In addition, call the return date as \"rd\" (return date)\n",
    "\n",
    "## Note that yyyymm indicates year and month of return date (not event date)\n",
    "eventret['edate']=pd.to_datetime(eventret['Date'].astype(int).astype(str),format='%Y%m%d')\n",
    "\n",
    "eventret['rd']=pd.to_datetime(eventret['rdate'])\n",
    "\n",
    "##yyyymm is the year-month of returns\n",
    "eventret['yyyymm']=eventret.rd.dt.year*100+eventret.rd.dt.month\n",
    "print(eventret.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cc12f-7780-4a65-86d1-30d8d1d5c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import *\n",
    "\n",
    "## You can use the \"relativedelta\" fundtion to find out\n",
    "## the date corresponding to a certain number of months \n",
    "#  plus (or minus) a certain date.  \n",
    "# (MonthEnd() is not used here since event date is not necessarily the end of a month)\n",
    "\n",
    "##Find out the date 24 months after the event date\n",
    "\n",
    "## \"e24\" is the date 24 months after the event date\n",
    "## eyyyymm and e24yyyymm are year and months of event date and 24 months after the corresponding event date.\n",
    "\n",
    "\n",
    "#appy.(lambda x: f(x)) is used to run f(x) function \n",
    "# for each observation of a column (here, eventret.edate)\n",
    "\n",
    "\n",
    "eventret['e24']=eventret.edate.apply(lambda x: x+relativedelta(months=+24))\n",
    "#check whether e24 is correct\n",
    "print(eventret[['edate','e24']])\n",
    "\n",
    "# eyyyymm and e24yyyymm are year and months of event date and 24 months after the corresponding event date.\n",
    "eventret['eyyyymm']=eventret.edate.dt.year*100+eventret.edate.dt.month\n",
    "eventret['e24yyyymm']=eventret.e24.dt.year*100+eventret.e24.dt.month\n",
    "\n",
    "#Check the output of eventret\n",
    "print(eventret.head())\n",
    "print(eventret.tail())\n",
    "print(eventret[['ID','edate','yyyymm','e24','rd','eyyyymm','e24yyyymm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4934e1-9fea-4214-9bd5-09f41883e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare the results with those using MonthEnd()\n",
    "eventret['e24a']=eventret.edate+MonthEnd(+24)\n",
    "print(eventret[['edate','e24','e24a']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f5d8a-2112-47ac-9bd5-3c98c5c0884b",
   "metadata": {},
   "source": [
    "## Calculate calendar time portfolio return\n",
    "\n",
    "The portfolios are composed of firms with the events that occurred within the past 24 months\n",
    "\n",
    "Find out the list of the stocks that satisfy the condition in each month\n",
    "\n",
    "In each month, id will be listed if it satisfy the condition in where i.e., return date is within the 24-month window starting from the month after event month.\n",
    "\n",
    "#### **distinct** is used in the \"select\" statement to select only unique observations (prevent same values to be selected multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1c0d5-9dd9-4db9-b365-32d8970f87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the eventret dataframe to an Excel file\n",
    "# This will create an Excel file named 'eventret.xlsx' in the current directory\n",
    "eventret.to_excel('./eventret.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a5626-0402-4c8e-953d-1015edc9ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eventret.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d8401-767a-47e0-9873-aba22f2da270",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Notice the use of \"distinct\" here\n",
    "## If not used, it can list the same yyyymm id row mutiple times\n",
    "\n",
    "## Note that the conditions in the \"where\" statement dictates which observations to include\n",
    "## based on yyyymm, event yyyymm (eyyyymm) and 24 months after the event yyyymm (e24yyyymm)\n",
    "\n",
    "print(eventret.columns)\n",
    "\n",
    "query='''select distinct a.yyyymm, a.id\n",
    "                  from eventret as a\n",
    "                  where  a.yyyymm > a.eyyyymm and a.yyyymm <= a.e24yyyymm\n",
    "                  order by a.yyyymm,a.id'''\n",
    "\n",
    "portdat=pysqldf(query)\n",
    "print(portdat.head())\n",
    "print(portdat.iloc[20:50,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646de2a8-b64c-4a05-8334-d6864cf81b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We are now ready to calculate the calendar time portfolio returns\n",
    "### We will calculate the equally- and value-weighted returns in each month\n",
    "\n",
    "## calcualte the equally- and value-weighted calendar time portfolio returns in each month\n",
    "## after joining market cap information.\n",
    "\n",
    "query='''select a.yyyymm, sum(b.return)/count(b.return) as ewret,\n",
    "                  sum(b.return*b.lmc)/sum(b.lmc) as vwret, count(b.return) as numstock\n",
    "                from portdat as a \n",
    "                left join marketcap as b\n",
    "                on  (a.id=b.id and a.yyyymm=b.yyyymm)\n",
    "                group by a.yyyymm\n",
    "                order by a.yyyymm'''\n",
    "\n",
    "calret=pysqldf(query)\n",
    "print(calret.head())\n",
    "print(calret.tail())\n",
    "print(calret.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dbc1c-1159-4ce9-aa2e-1ca6adcbd4b4",
   "metadata": {},
   "source": [
    "# P/B portfolio formation and return calculation\n",
    "\n",
    "Input files used\n",
    "\n",
    "    - 2020SP500Constituents_2025_Short.xlsx\n",
    "\n",
    "We will make 3 dataframes (return, market cap and MB ratios) out of the input file and then combine them to calculate portfolio returns\n",
    "\n",
    "2020SP500Constituents_2025.xlsx file includes the list of firms included in S&P 500 as of 2020 and other information of these firms (returns, market capitalization and market-to-book equity ratio) retrieved from Bloomberg in Excel as will be discussed in Note6W.  You will find that the information can be retrieved directly from Bloomberg using API as will be discussed in Note6W (and shown in FDNote6W2025.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac06b27",
   "metadata": {},
   "source": [
    "#### First, Make Return Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97750d1-9ae8-4a5f-8981-aeef63a38111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "########read the return data\n",
    "#########################################################\n",
    "returns=pd.read_excel('./2020SP500Constituents_2025_Short.xlsx', sheet_name=\"Returns\", header=0)\n",
    "print(returns.columns[:5])\n",
    "print(returns.iloc[:5,:5])\n",
    "\n",
    "#discard the first three columns\n",
    "returns=returns.iloc[:,3:].copy()#The first one is row and the second one is column\n",
    "print(returns.columns[:5])\n",
    "print(returns.iloc[:5,:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7821d-0209-45c1-83fd-e566cab7fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select only those with available \"Edate\" information and rename \"Edate\" as \"date\"\n",
    "ret0=returns.dropna(subset=['Edate']).copy()#drop all rows with Edate=NaN\n",
    "\n",
    "#Rename\n",
    "# it is important to use inplace=True to change the original dataframe\n",
    "ret0.rename(columns={'Edate': 'date'}, inplace=True)\n",
    "\n",
    "##check\n",
    "print(ret0.shape)\n",
    "print(ret0.columns)\n",
    "print(ret0.columns.values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62a095-e558-4673-abdb-32fd625fe2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##sort by date\n",
    "ret0sort=ret0.sort_values(['date'])\n",
    "\n",
    "print(ret0sort.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a22169",
   "metadata": {},
   "source": [
    "#### Trasnpose the data to calculate portfolio returns\n",
    "\n",
    "In the current format, returns are across different columns.\n",
    "To calculate portfolio returns, it is easy to have returns in one column, not across different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af3436-0257-448e-96fe-eee98a67726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##transpose the data (column names are called \"id\" and values are called \"ret\")\n",
    "# pd.melt() is used to reshape the DataFrame\n",
    "# It converts the DataFrame from wide format to long format\n",
    "\n",
    "#id_vars=['date'] specifies the columns to keep as identifiers\n",
    "#var_name='id' specifies the name of the new column that will contain the former column names\n",
    "#value_name='ret' specifies the name of the new column that will contain the former values\n",
    "\n",
    "returns0=pd.melt(ret0sort,id_vars=['date'],var_name='id',value_name='ret')\n",
    "\n",
    "#check the first few rows and the rows with ret=-99\n",
    "print(returns0.head())\n",
    "print (returns0.loc[returns0['ret']==-99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306cb425-9b95-4c4a-99e4-82d321a453f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the row at index 352\n",
    "# This will show the data for the specific date and id at that index\n",
    "print(returns0.iloc[352,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265faa6d-fee6-4feb-ace5-2cf259a97fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Replace the \"ret\" column values of -99 as missing returns\n",
    "returns0.loc[returns0['ret']==-99,'ret']=np.nan\n",
    "### convert the return in % to decimal by dividing the return values by 100\n",
    "returns0['ret']=returns0['ret']/100.0\n",
    "\n",
    "#check\n",
    "print(returns0.iloc[352,:])\n",
    "print(returns0.head())\n",
    "print(returns0.ret.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae0a4e-0210-4036-ac1e-404e88a3acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use query to check summary statistics of monthly returns\n",
    "\n",
    "query='''\n",
    "        select avg(a.ret) as avg, count(a.ret) as num,\n",
    "            sum(a.ret) as sum, min(a.ret) as min, max(a.ret) as max\n",
    "        from returns0 as a\n",
    "        where a.ret not null\n",
    "    '''\n",
    "print(pysqldf(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f9b06d",
   "metadata": {},
   "source": [
    "#### Second, Make Market Cap Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd9613-7c1f-4357-85db-83d21b2b7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the market capitalization information \n",
    "## and drop the observations without Bdate and rename Bdate as date.\n",
    "## Bdat is the date of market cap calculation in the \"MarketCap\" worksheet (Edate is a month after Bdate)\n",
    "\n",
    "mc=pd.read_excel('./2020SP500Constituents_2025_Short.xlsx', sheet_name=\"MarketCap\", header=0)\n",
    "print(mc.columns[:5])\n",
    "mc=mc.iloc[:,2:]#skip the first two columns\n",
    "print(mc.columns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf77ecd-2401-4d28-87f2-b6ac1c7bcf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=mc.drop(['Edate'],axis=1) #drop the Edate column\n",
    "\n",
    "##In the data, market cap is the market cap on Bdate\n",
    "mc.rename(columns={'Bdate': 'date'}, inplace=True)#rename Bdate column as date\n",
    "mc=mc.dropna(subset=['date'])#if date is missing, drop\n",
    "mcsort=mc.sort_values(['date'])#sort by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c8cde-2280-4c03-b5fd-71eb5c19140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcsort.iloc[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dddfe23-41ce-45a0-9d81-181371267cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.melt: This function is useful to massage a DataFrame into a format where one or more\n",
    "# columns are identifier variables (id_vars), while all other columns, \n",
    "#considered measured variables (value_vars), are “unpivoted” to the row axis, \n",
    "#leaving just two non-identifier columns, ‘variable’ and ‘value’.\n",
    "\n",
    "mc0=pd.melt(mcsort,id_vars=['date'],var_name='id',value_name='mcap')#change the format\n",
    "mc0.loc[mc0['mcap']==0.0,'mcap']=np.nan\n",
    "mc0sort=mc0.sort_values(['id','date']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#check\n",
    "print(mc.iloc[:5,:5])\n",
    "#print(mc.columns.values[:5])\n",
    "#print(mc.shape)\n",
    "\n",
    "print(mc0sort.iloc[:5,])\n",
    "#print(mc0.loc[mc0['mcap']==0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575c140",
   "metadata": {},
   "source": [
    "#### Third, Make M/B Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7192c-64a0-4fd9-bc45-d99c1ad4c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########for m/b  ###################################################################################\n",
    "\n",
    "##In the MB worksheet, Edate is the date of market cap to book value information.\n",
    "\n",
    "mb=pd.read_excel('./2020SP500Constituents_2025_Short.xlsx', sheet_name=\"MB\", header=0)\n",
    "print(mb.columns[:5])\n",
    "mb=mb.iloc[:,2:]#skip the first two columns\n",
    "print(mb.columns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375657e-7a6f-4f38-8966-52a7ac313fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the MB data as we did for other data\n",
    "\n",
    "mb.rename(columns={'Edate': 'date'}, inplace=True)#rename Edate columns\n",
    "mb=mb.dropna(subset=['date'])#drop if date is missing\n",
    "mbsort=mb.sort_values(['date'])# sort by date\n",
    "mb0=pd.melt(mbsort,id_vars=['date'],var_name='id',value_name='mb')#change the format\n",
    "mb0['year']=mb0['date'].dt.year#get year out of date and make it \"year\" column\n",
    "\n",
    "#check\n",
    "#print(mb.columns.values[:5])\n",
    "print(mb.shape)\n",
    "print(mb0.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f731a9-3cfa-43f9-bc09-11094f7d6b39",
   "metadata": {},
   "source": [
    "#### Drop rows with missing mb values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1d97b-f83a-4dab-ab5d-9287ecd48ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mb0.shape)\n",
    "mb1=mb0.dropna(subset=['mb'])#drop those with missing mb\n",
    "print(mb1.shape)\n",
    "print(mb1.groupby(['date'])['mb'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1adbb-fbff-4dc8-8e05-156545fa2445",
   "metadata": {},
   "source": [
    "##### Find the cutoff points for MB quintiles (5 groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbde6a-c5c2-4c8d-be07-7a3e364038f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, find out the percentile values of MB ratios in each month\n",
    "mb2 = mb1.groupby(['date'])['mb'].describe(percentiles=[.2, .4, .6,.8]).reset_index()\n",
    "print(mb2.head())\n",
    "\n",
    "# Second, rename the columns for easier access\n",
    "mb2 = mb2[['date','20%','40%','60%','80%']]\\\n",
    ".rename(columns={'20%':'quint20','40%':'quint40','60%':'quint60','80%':'quint80'})\n",
    "\n",
    "print(mb2.columns)\n",
    "print(mb2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33ab41-faa0-4d6c-8517-19a079327fb2",
   "metadata": {},
   "source": [
    "Add quintile cutoff points and divide firms in to 5 groups based on mb;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece8238-c02f-418f-8202-f560d14c875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cutoff points to the original mb data\n",
    "# Note that columns to be included are selected from mb0 to avoid\n",
    "# date column being duplicated in the result (both a and b have the date column)\n",
    "query='''select a.id,a.mb,a.year,b.*\n",
    "              from mb0 as a \n",
    "              left join mb2 as b \n",
    "              on a.date = b.date'''\n",
    "              \n",
    "mb3=pysqldf(query)\n",
    "print(mb3.columns)\n",
    "print(mb3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f201d9-cd67-433c-8344-6c6dbb1404b3",
   "metadata": {},
   "source": [
    "### Use SQL to form portfolios and calculate returns of the portfolio composed of all stocks in each portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e49ca2-9c6a-4cfd-b724-33489b7a1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find out which MB portfolios each stock belongs to in each year\n",
    "\n",
    "# Assgin firms into 5 groups based on mb using SQL;\n",
    "# Note that \"case when\" is used to assign a value based on a condition\n",
    "# new column \"pmb\" is the portfolio based on mb\n",
    "\n",
    "query='''select a.*,\n",
    "                case when a.mb <= a.quint20 then 1 else \n",
    "                    case when a.mb <= a.quint40 then 2 else\n",
    "                        case when a.mb <= a.quint60 then 3 else\n",
    "                            case when a.mb <= a.quint80 then 4 else 5\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                end as pmb\n",
    "            from mb3 as a'''\n",
    "mb3a=pysqldf(query)\n",
    "print(mb3a.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4cc0d6-63e8-4afc-9795-554053bd4b29",
   "metadata": {},
   "source": [
    "# Combine 3 dataframes\n",
    "\n",
    "Add new variables\n",
    "\n",
    "To combine data for each month, we create year and month columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b6fa0-4a9d-49f5-8d94-58172c6d98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/*combine the data*/\n",
    "mb5=mb3a[mb3a['mb'].notnull()].copy()# Get rid of ones with missing mb values\n",
    "\n",
    "print(mb5.date)\n",
    "#the following change the format of date to a simmpler datetime format\n",
    "mb5['date']=pd.to_datetime((mb5['date']).astype(str))\n",
    "print(mb5.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef22a9c5-e45c-4966-92bf-221506be0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year and month columns\n",
    "\n",
    "returns0['year']=returns0['date'].dt.year\n",
    "mc0sort['year']=mc0sort['date'].dt.year\n",
    "mb5['year']=mb5['date'].dt.year\n",
    "\n",
    "returns0['month']=returns0['date'].dt.month\n",
    "mc0sort['month']=mc0sort['date'].dt.month\n",
    "mb5['month']=mb5['date'].dt.month\n",
    "\n",
    "print(returns0.head())\n",
    "print(mb5.head())\n",
    "print(mc0.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c23c97-3599-4861-a265-26757a1618d4",
   "metadata": {},
   "source": [
    "### Combine three data sets \n",
    "\n",
    "- yyyymm is the year-month of return\n",
    "- mcapym is the year-month of market cap to be used for weights in vw\n",
    "- mbym is the year-month of mb portfolio\n",
    "\n",
    "mb portfolio is formed at the end of June and this is used from July of the year till June of the following year in portfolio formation.\n",
    "\n",
    "Note the conditions used in join \"on\"\n",
    "\n",
    "- When you combine the return datafreame and the market cap dataframe, make sure that the market cap is the market cap at one month before the return month.\n",
    "    - ((a.year-b.year)*12+(a.month-b.month)) =1: To make sure that lagged market cap is indeed the market cap one month prior to the return month: \n",
    "        - b (mc0sort)' year/month is the year/month for market cap and \n",
    "        - a (returns0)'s year/month is the year/month for returns\n",
    "- When you combine the return dataframe and the MB portfolio dataframe, make sure that returns are included from July of the MB portfolio formation year and June of the following year (Portfolios are formed in June of each year)\n",
    "    - ((a.year-c.year)*12+(a.month-c.month)) between 1 and 12: To combine June BM of year t with returns from July of year t to June of year t+1: \n",
    "        - c (mb5)'s year/month is the year/month for market-to-book ratio and \n",
    "        - a (returns0)'s year/month is the year/month for returns (returns are included from one month after untill twelve months after the market-to-book calculation month.\n",
    "\n",
    "Check a simpler way used to retrive M/B ratios and other information using Bloomber API in the next week's notebook, FDNote6W2025.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea44c2-9695-45a0-84c5-9f6830315549",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine the returns, market cap, and mb dataframes using SQL\n",
    "# Note the conditions used in join \"on\" as explained above\n",
    "# The conditions make sure that the mcap is the market cap one month prior to the return month\n",
    "# and that returns are included from July of the MB portfolio formation year and June of the following\n",
    "\n",
    "query='''select a.date,a.year*100+a.month as yyyymm,a.id\n",
    "            ,a.ret,b.mcap,c.mb,c.pmb,\n",
    "            b.year*100+b.month as mcapym,\n",
    "            c.year*100+c.month as mbym\n",
    "         from returns0 as a\n",
    "         left join mc0sort as b on ((a.year-b.year)*12+(a.month-b.month)) =1 and a.id=b.id \n",
    "         left join mb5 as c on a.id=c.id and ((a.year-c.year)*12+(a.month-c.month)) between 1 and 12\n",
    "         order by a.id,a.date'''\n",
    "              \n",
    "data=pysqldf(query)\n",
    "print(data.head())\n",
    "print(data[data.ret.notnull()].head())#print only those with non-missing ret\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd132e7-d5bb-42ba-8f3a-1c74fbe5b7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###check whether mcapym is the previous month (market cap), \n",
    "## and mbym (year/month of MB calculation) changes in July\n",
    "print(data.loc[data.pmb.notnull(),['date','mcapym','mb','pmb','mbym','id','yyyymm','mcapym','mbym']].reset_index(drop=True).head(50))\n",
    "#############################################################################             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823995ad-0d2d-40d0-989b-77c615245447",
   "metadata": {},
   "source": [
    "#### Calculate the value-weighted and equally-weighted returns \n",
    "using only thoe with available return and portfolio information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bbc021-ee6a-4430-b34e-fde87c1ed252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/*calculate returns of the portfolio*/\n",
    "##Note that in the data, mcap is the market cap at the end of the month prior to the return month\n",
    "##Therefore, we do not need to use the lagged market cap.\n",
    "\n",
    "#Include only thoes with non-missing return, pmb and market cap\n",
    "#An additional condition is that pmb is not 0\n",
    "\n",
    "data1=data.loc[(data.ret.notnull() & data.pmb.notnull() &\\\n",
    "                data.pmb!=0 & data.mcap.notnull()),:].reset_index(drop=True).copy()\n",
    "# Check the number of rows and columns before and after filtering\n",
    "print(\"Before filtering:\", data.shape)\n",
    "print(\"After filtering:\", data1.shape)\n",
    "print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9118a0f2-35d3-4d73-8cb7-2155930bed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to calculate the portfolio returns\n",
    "# Note that the portfolio returns are calculated in each month (yyyymm)\n",
    "\n",
    "# calculate equally- and value-weighted returns \n",
    "# of each pmb portfolio in each month\n",
    "\n",
    "query='''select a.yyyymm, a.pmb, sum(a.ret)/count(a.ret) as ewret,\n",
    "             sum(a.ret*a.mcap)/sum(a.mcap) as vwret,count(a.ret) as numstock\n",
    "         from data1 as a\n",
    "         group by a.yyyymm, pmb\n",
    "         order by a.yyyymm, pmb'''              \n",
    "ret=pysqldf(query)\n",
    "print(ret.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c3af5-01c5-4061-aa73-2846c33132b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "###Calculate the average returns of each PMB group\n",
    "###Note that below is the average of average returns\n",
    "query='''select a.pmb, avg(ewret),avg(vwret),count(vwret) as num\n",
    "             from ret as a\n",
    "             group by pmb'''\n",
    "avg=sqldf(query,locals())\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c062dea-2534-4ccd-ac59-c84966088ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ret.groupby('pmb')[['ewret','vwret']].mean())\n",
    "print(ret.groupby('pmb')[['ewret','vwret']].describe())\n",
    "\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90886b3a-a36e-4de9-927f-cf761fdd7529",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Appendix \n",
    "\n",
    "Below are just for reference\n",
    "\n",
    "- How to calculate returns using price information\n",
    "- How to calcualte value-weighted returns using a function\n",
    "- How to form MB portfolios using Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf55af7-7f3b-422b-bd0a-4ccb270fa7b9",
   "metadata": {},
   "source": [
    "## Appendix 1: Calculate returns using price information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf3550-2208-4d14-9046-1ccf20b24723",
   "metadata": {},
   "outputs": [],
   "source": [
    "########read the company id in the first row#########################################################\n",
    "LowPEHead=pd.read_excel('./Note3w_RHistory2025_Short.xlsx', sheet_name=\"RHistory\", skiprows=0,nrows=1,header=None)\n",
    "print(LowPEHead.iloc[:,0:5].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f475e71-16fb-4cd7-8e1f-166faeb75323",
   "metadata": {},
   "outputs": [],
   "source": [
    "########read the price data                 #########################################################\n",
    "####Skip the first 3 rows\n",
    "LowPE=pd.read_excel('./Note3w_RHistory2025_Short.xlsx', sheet_name=\"RHistory\", skiprows=3,header=None)\n",
    "print(LowPE.iloc[:,0:5].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595539f7-e303-4d9b-9500-6089f30b7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the column headings\n",
    "##replace column names with the one in LowPEHead\n",
    "LowPE.columns=LowPEHead.iloc[0,:]\n",
    "print(LowPE.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803ff48-1ec5-48a2-aa37-b86c664ffbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rename the first column as date\n",
    "LowPE.rename(columns={ LowPE.columns[0]: \"date\"}, inplace=True)\n",
    "print(LowPE.shape)\n",
    "print(LowPE.iloc[:,0:5].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992b6ef-dc4d-4f18-8683-4b613158f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LowPE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9128b4-35ea-4d53-93e0-190ce83f6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "###eliminate columns with all NA\n",
    "LowPE.dropna(axis=1,how='all',inplace=True)\n",
    "print(LowPE.shape)\n",
    "print(LowPE.columns)\n",
    "print(LowPE.head())\n",
    "print(LowPE.describe().T)# by using .T you can transpose the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a230e-871a-4ffd-b7eb-7889e9bdb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### transpose the data #######################################################################\n",
    "trans=pd.melt(LowPE,id_vars=['date'],var_name='id',value_name='price')\n",
    "print(trans.head())\n",
    "trans.sort_values(['id','date'],inplace=True)\n",
    "trans.reset_index(drop=True,inplace=True)\n",
    "print(trans.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ef6bb-edd9-4229-98c9-d8739578c1d0",
   "metadata": {},
   "source": [
    "### One can create new columns as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bdb0f-57b2-4cdc-a253-c6cba37139b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lagged values for each id\n",
    "trans[['lprice','ldate']]=trans.groupby(['id'])[['price','date']].shift(1)\n",
    "trans.reset_index(drop=True,inplace=True)# reset the index and drop old index values.  In addition, replace the original\n",
    "print(trans.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636fadd-966a-42a2-824e-1d1e8849827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate returns\n",
    "trans['return']=(trans['price']-trans['lprice'])/trans['lprice']\n",
    "#create aYearMonth columns\n",
    "trans['yyyymm']=trans['date'].dt.year*100+trans['date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc18bb9-70f1-4464-ae3b-005cad9bae30",
   "metadata": {},
   "source": [
    "### One should be careful not to mistakenly calcualted returns using prices of different companies\n",
    "- It can happen when ID changes\n",
    "- In addition, returns may not represent the return over the intended time interval (e.g., a month) when there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd643016-8707-4778-969a-f0ad046aab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find the differences in the number of months between the lagged observation and the current one\n",
    "# and eliminate those with more than one month difference\n",
    "\n",
    "trans['diffm']=(trans['date'].dt.year-trans['ldate'].dt.year)*12+\\\n",
    "                (trans['date'].dt.month-trans['ldate'].dt.month)\n",
    "print(trans.head())\n",
    "print(trans.dtypes)#types of each column values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f30796-05d3-4938-a435-43627a149cb6",
   "metadata": {},
   "source": [
    "#### If the gap between the current and the previous month is greater than one month, set the return as missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989deb95-a747-4e96-b782-a294db3894fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trans['return'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f722d4c-fc57-470c-9937-7e306ae0ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.loc[(trans['diffm']!=1.0),'return']=np.nan\n",
    "print(trans['return'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985755fd-08fd-4d3d-ac62-816fb1123d8b",
   "metadata": {},
   "source": [
    "## Use \"groupby\" to correctly calculate returns using prices\n",
    "\n",
    "Below, you will find that **ret** includes wrong returns when ID changes to a different one while **ret1** and **ret2** correctly calculate returns even when ID changes (missing in those cases) by using **groupby(['id'])**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6a307-540e-4e85-8634-82ccd234fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate returns in a simpler way\n",
    "#Problem with a new ID\n",
    "trans['ret']=(trans['price']-trans['price'].shift(1))/trans['price'].shift(1)\n",
    "print(trans.ret.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59eb562-a4f8-4e0c-9fc6-c9597b5e05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above code does not work correctly for the first observation of each ID\n",
    "#because it uses the previous observation of the same ID\n",
    "#Therefore, we need to use groupby to calculate the returns for each ID separately\n",
    "#This will ensure that the return is calculated based on the previous observation of the same ID\n",
    "\n",
    "#Correct one\n",
    "#############################################\n",
    "trans['ret1']=(trans['price']-trans.groupby(['id'])['price'].shift(1))\\\n",
    "                /trans.groupby(['id'])['price'].shift(1)\n",
    "print(trans.ret1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28960c23-b55a-48db-b738-8774807948ea",
   "metadata": {},
   "source": [
    "#### One can use \".pct_change()\" to find the return with \"groupby\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76535cf3-2d02-4bb2-b59c-7e183a4e8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#trans['ret2']=trans.price.pct_change(fill_method=None)\n",
    "trans['ret2']=trans.groupby(['id']).price.pct_change()\n",
    "print(trans.ret2.describe())\n",
    "print((trans.ret2-trans.ret1).describe())\n",
    "\n",
    "print(trans[['id','date','ret','ret1','ret2']].head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99aeb6-8e2d-4bdc-ae3b-3d3d0e8df2a8",
   "metadata": {},
   "source": [
    "## Appendix 2: How to calculate value-weighted returns using a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ef218-60c0-4e6e-b430-8766774a4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Using pandas##########################################\n",
    "# One can define a custom function to calculate value weighted return\n",
    "#df is a dataframe, avg_name is the column name to be used for average calculation\n",
    "#weight_name is the column name to be used as the weight in value-weighted average\n",
    "\n",
    "def wavg(df, avg_name, weight_name):\n",
    "    df = df[df[avg_name].notna() & df[weight_name].notna()].copy()  # Filter out NaN values\n",
    "    if df.empty:\n",
    "        return np.nan\n",
    "    d = df[avg_name]\n",
    "    w = df[weight_name]\n",
    "    \n",
    "    try:\n",
    "        w_sum = w.sum()\n",
    "        if w_sum == 0 or np.isnan(w_sum) or np.isinf(w_sum):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return (d * w).sum() / w_sum\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "# Calculate Weighted Average Returns \n",
    "# to use the custom function defined above for each group of yyyymm and pmb\n",
    "# one can use the apply method with a lambda function\n",
    "\n",
    "data1.groupby(['yyyymm', 'pmb'])[['ret', 'mcap']].apply(lambda x: wavg(x, 'ret', 'mcap')).reset_index()\n",
    "data1['icount']=np.where(data1['ret'].notnull(),1,0)#icount is set to be 1 if ret is not null.  Otherwise, set to be zero\n",
    "print(data1.icount.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eccfa-ef47-4325-afed-8f9bcfe76d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret['vwret1']= data1.groupby(['yyyymm','pmb'])[['ret','mcap']].apply(wavg, 'ret','mcap').reset_index().iloc[:,2]\n",
    "\n",
    "# Equally-weighted returns are calculated by using the same function\n",
    "# where the weight is same for all (i.e., 1) in each group\n",
    "\n",
    "ret['ewret1'] = data1.groupby(['yyyymm','pmb'])[['ret','icount']].apply(wavg, 'ret','icount').reset_index().iloc[:,2]\n",
    "print(ret.head(20))\n",
    "\n",
    "###Compare the results calculated using SQL above\n",
    "print((ret.ewret-ret.ewret1).describe())\n",
    "print((ret.vwret-ret.vwret1).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d47434-0f7f-4897-a935-9bcdceba59d5",
   "metadata": {},
   "source": [
    "## Appendix 3: The following are alternative ways to find out the MB portfolios in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61becc6-d91e-4e10-b4c5-ae0fbe95d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following are alternative ways to find the portfolios in Python\n",
    "#assign MB portfolio value - define a function\n",
    "\n",
    "# Define a function to assign quintiles based on the mb value\n",
    "def quintile(x):#note that the input is a dataframe\n",
    "    \n",
    "    if x['mb'] <= x['quint20']: return 1\n",
    "    elif x['mb'] <= x['quint40']: return 2\n",
    "    elif x['mb'] <= x['quint60']: return 3\n",
    "    elif x['mb'] <= x['quint80']: return 4\n",
    "    else: return 5\n",
    "mb3['pmb']=mb3.apply(quintile, axis=1)#apply the function and call the result as pmb\n",
    "mb3['pmb']=np.where(mb3['mb'].isnull(),0,mb3['pmb'])#If mb is null assign 0\n",
    "\n",
    "#check\n",
    "print(mb3.columns)\n",
    "print(mb3.head())\n",
    "#print(mb3[mb3['mb'].isnull()].head())\n",
    "#print(mb3[mb3['mb'].notnull()].head())\n",
    "#print(mb3.mb.describe())\n",
    "#print(mb3[mb3.pmb>0].pmb.describe())\n",
    "print(mb3.groupby(['pmb']).mb.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80a93d-ecc8-4df7-9f0c-294ce5a67af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# An easier way using pandas' qcut to form deciles in each year\n",
    "######################################################################\n",
    "print(mb3.shape)\n",
    "mb4=mb3[mb3['mb'].notnull()].copy()# Get rid of ones with missing mb values\n",
    "print(mb4.shape)\n",
    "\n",
    "#lambda \"arguments\" : \"expression\"\n",
    "#The \"expression\" with \"argument\" is executed and the result is returned:\n",
    "\n",
    "\n",
    "#\".transform(lambda x: f(x))\" is similar to .apply(lambda x: f(x)) but keep the original shape\n",
    "# while apply does not\n",
    "mb4.loc[:,'mbquint']=mb4.groupby(['year'])['mb'].transform(\n",
    "                     lambda x: pd.qcut(x, 5, labels=range(1,6)))\n",
    "\n",
    "print(mb3.columns)\n",
    "print(mb4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6574a3-ae75-4853-ade7-a4c2d3270cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mb4[['pmb','mbquint']])\n",
    "print(mb4.dtypes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
