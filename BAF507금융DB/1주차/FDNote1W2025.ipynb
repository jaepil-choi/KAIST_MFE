{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162b0e15",
   "metadata": {},
   "source": [
    "## FDNote1W.ipynb\n",
    "Prepared by Inmoo Lee for the Financial Databases class at KAIST\n",
    "inmool@kaist.ac.kr\n",
    "\n",
    "List of input files\n",
    "\n",
    "    - note1.txt\n",
    "    - note1test.xlsx\n",
    "    - note1data.xlsx\n",
    "    - note1.RData\n",
    "\n",
    "List of output files\n",
    "\n",
    "    - note1_out.xlsx\n",
    "    - note1.pkl\n",
    "    - note1.ft\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753059f3",
   "metadata": {},
   "source": [
    "### Package \n",
    "\n",
    "To use packages, you need to install them first.\n",
    "\n",
    "Reference the following for the installation of pakcages \n",
    "https://www.youtube.com/watch?v=Z_Kxg-EYvxM \n",
    "\n",
    "When you have problems with installing packages using conda, reference the following\n",
    "\n",
    "https://docs.conda.io/projects/conda/en/latest/user-guide/configuration/use-condarc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d195ff",
   "metadata": {},
   "source": [
    "## Set the working environment\n",
    "\n",
    "If a pakcage is not installed, then you have to install it first using \"!pip install ***\" or \"conda install ***\" in Ananconda Powershell Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f53e5-70fb-449c-b4cb-9d7d2e6f6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #import a package called os\n",
    "\n",
    "print(os.getcwd())  #get the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fae3e-71c8-4d50-b83b-336b23291ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"d:\\\\****\\\\\"# specify the path to change to in your computer\n",
    "os.chdir(path) # change the working directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ec6c1",
   "metadata": {},
   "source": [
    "## Data input/import\n",
    "\n",
    "##### Some basic commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=100 #define the value of a variable\n",
    "miles=1000.0\n",
    "name=\"John\"\n",
    "\n",
    "print (counter) #print out to the output screen\n",
    "print(miles)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the variables\n",
    "print(type(counter))\n",
    "print(type(miles))\n",
    "print(type(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667aa9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [ 'abcd', 786 , 2.23, 'john', 70.2 ] #series\n",
    "tinylist = [123, 'john']\n",
    "\n",
    "print(list) # Prints complete list\n",
    "print(tinylist) #Prints list two times\n",
    "\n",
    "print(list[1]) #Prints first element of the list\n",
    "print(list[1:4]) #Prints elements starting from 2nd till 3rd\n",
    "print(list[2:]) #Prints elements starting from 3rd element\n",
    "print(tinylist*2) #Prints list two times\n",
    "print(list + tinylist) #Prints concatenated lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the list variables\n",
    "print(type(tinylist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2c588",
   "metadata": {},
   "source": [
    "### Dictionary\n",
    "\n",
    "Composed of keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {} # Create an empty dictionary\n",
    "dict['one'] = \"This is one\"\n",
    "dict[2]     = \"This is two\"\n",
    "\n",
    "tinydict = {'name': 'john','code':6734, 'dept': 'sales'}\n",
    "\n",
    "\n",
    "print (dict['one'])       # Prints value for 'one' key\n",
    "print (dict[2])           # Prints value for 2 key\n",
    "print (tinydict)          # Prints complete dictionary\n",
    "print (tinydict.keys())   # Prints all the keys\n",
    "print (tinydict.values()) # Prints all the values\n",
    "print(dict.keys())\n",
    "print(dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the dictionary variables\n",
    "print(type(dict))\n",
    "print(type(tinydict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12ab0e",
   "metadata": {},
   "source": [
    "## Create and read data\n",
    "\n",
    "####  Method 1: Create one directly\n",
    "\n",
    "First, import packages after installing packages (if not installed yet, you can install inside jupyternote by using the following command\n",
    "\n",
    "!pip install numpy\n",
    "\n",
    ")\n",
    "\n",
    "Combine arrays and create a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a9414b-4b12-43dc-ad2e-da3b62953f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c826bef8-3b15-4d8a-bee0-222b3a3bfbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array((1,2,3,4,5))\n",
    "print(d)\n",
    "e=np.array((\"M\", \"F\", \"F\", \"M\", \"F\"))\n",
    "f=np.array((68.5, 50.2, 45.5, 80.5, 55.0))\n",
    "g=np.array((175, 150, 155, 165, 160))\n",
    "print(np.column_stack((d,e,f,g)))\n",
    "\n",
    "test1=pd.DataFrame(data=np.column_stack((d,e,f,g)),columns=[\"ID\", \"GENDER\", \"WEIGHT\", \"HEIGHT\"])\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70212eaa",
   "metadata": {},
   "source": [
    "### Choose a particular column or row in a dataframe\n",
    "\n",
    "**loc** gets rows (or columns) with particular labels from the index.\n",
    "**iloc** gets rows (or columns) at particular positions in the index (so it only takes integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test1.columns)\n",
    "print(test1.loc[0:0,:])\n",
    "print(test1.iloc[0:1,:])\n",
    "print(test1.iloc[:,0:2])\n",
    "print(test1.loc[:,['ID','HEIGHT']])\n",
    "print(test1.iloc[:,0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7936f",
   "metadata": {},
   "source": [
    "###  Method 2: Read from a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bbfdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=pd.read_csv(\"./note1.txt\", sep=\" \", header=None, names=[\"ID\", \"GENDER\", \"WEIGHT\", \"HEIGHT\"])\n",
    "print(test2)\n",
    "type(test2) #print out the type of variable, series or file\n",
    "\n",
    "#test2.index=[\"row1\", \"row2\", \"row3\", \"row4\",\"row5\"]#for the naming of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01ccda",
   "metadata": {},
   "source": [
    "###  Method 3: Read from an Excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c72af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3=pd.read_excel('./note1test.xlsx', sheet_name=\"TEST3\", header=0)\n",
    "print(test3)\n",
    "print(test3.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de7584",
   "metadata": {},
   "source": [
    "### Save the data to a DataFrame file using pandas\n",
    "\n",
    "Compare different formats: e.g., check the class note for comparisons of alternative file formats (CSV, Excel, JSON, HDF5, Feather, Parquet and Pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec39846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the dataframe to an pickle format file\n",
    "test3.to_pickle(\"./note1.pkl\") #To save in the pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11398745-15fe-4c41-8c5d-6568075b9c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use different file formats such as feather or parquet, you need to install the respective libraries.\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec88539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alterantivealy, you can use feather\n",
    "test3.to_feather(\"./note1.ft\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22773142",
   "metadata": {},
   "source": [
    "### How to retrieve the saved data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can call the saved file in the following way\n",
    "test41=pd.read_pickle(\"./note1.pkl\")\n",
    "test42=pd.read_feather('./note1.ft')\n",
    "print(type(test41))\n",
    "print(type(test42))\n",
    "\n",
    "print(test3)\n",
    "print(test41)\n",
    "print(test42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fc770",
   "metadata": {},
   "source": [
    "### How to save to an Excel file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96843b3a-2807-4818-8d57-60a4f7e0eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save to a new excel file, you can use the following command\n",
    "\n",
    "test3.to_excel('./note1_out.xlsx', sheet_name='TEST4', index=False) #do not include index in the excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598827a8",
   "metadata": {},
   "source": [
    "### Conduct a simple analysis#\n",
    "\n",
    "#### Add a category variable\n",
    "\n",
    "define \"STATURE\" based on the value of HEIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68705aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test1.dtypes) # print the type of each columns\n",
    "print(test2.columns) #print the columns of the dataframe\n",
    "print(test2) #print the dataframe\n",
    "\n",
    "# Add a new column 'STATURE' based on the condition of HEIGHT\n",
    "# If HEIGHT is less than 160, then STATURE is 'Short', otherwise 'Tall\n",
    "test2.loc[:,'STATURE']=np.where((pd.to_numeric(test1.loc[:,'HEIGHT']) < 160), 'Short', 'Tall')\n",
    "#######################\n",
    "print(test2) #Check the updated dataframe with the new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1d052",
   "metadata": {},
   "source": [
    "### Alternatively, you can define a function to do the same\n",
    "\n",
    "Define func() to catogorize and then use **apply** to apply the function to a column of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to categorize height\n",
    "# If HEIGHT is less than 160, then STATURE is 'Short', otherwise 'Tall\n",
    "def func(x):            #x is an input\n",
    "    if int(x) < 160:    #int() convert x to integer value\n",
    "        return 'Short'  #assign the value to the function and return it\n",
    "    else:\n",
    "        return 'Tall'\n",
    "\n",
    "print(test1) #print the original dataframe\n",
    "# Apply the function to the HEIGHT column and create a new column STATURE\n",
    "test1.loc[:,'STATURE'] = test1.loc[:,'HEIGHT'].apply(func)\n",
    "print(test1) #Check the updated dataframe with the new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3632cf",
   "metadata": {},
   "source": [
    "### How to sort the data by the values of a column or columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0263f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort values by 'GENDER' in ascending order.\n",
    "testout=test1.sort_values([\"GENDER\",'WEIGHT'],ascending=True)\n",
    "print(testout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdecdee",
   "metadata": {},
   "source": [
    "### Calculate group means and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1107f-925f-48ef-b437-eb90043ace67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert an object type to a numeric value\n",
    "print(testout.dtypes)\n",
    "testout[\"WEIGHT\"]=pd.to_numeric(testout['WEIGHT'])\n",
    "testout[\"HEIGHT\"]=pd.to_numeric(testout['HEIGHT'])\n",
    "print(testout.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f152b709-a019-4872-a719-80b2da57d20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WEIGHT                                         HEIGHT                \\\n",
      "          sum       mean median   min   max       std    sum   mean median   \n",
      "GENDER                                                                       \n",
      "F       150.7  50.233333   50.2  45.5  55.0  4.750088    465  155.0  155.0   \n",
      "M       149.0  74.500000   74.5  68.5  80.5  8.485281    340  170.0  170.0   \n",
      "\n",
      "                            \n",
      "        min  max       std  \n",
      "GENDER                      \n",
      "F       150  160  5.000000  \n",
      "M       165  175  7.071068  \n"
     ]
    }
   ],
   "source": [
    "# After defining a dataframe grouped by variables of your choide, \n",
    "# you can use the agg() function to calculate various statistics\n",
    "# such as sum, mean, median, min, max, and std for the grouped data\n",
    "grouped=testout.groupby(['GENDER'])[['WEIGHT','HEIGHT']]\n",
    "print(grouped.agg(['sum','mean','median',\\\n",
    "                   'min','max','std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, you can use the following commands to get the statistics\n",
    "# for each group\n",
    "print(testout.groupby([\"GENDER\"])[['WEIGHT','HEIGHT']].mean())\n",
    "print(testout.groupby([\"GENDER\"])[['WEIGHT','HEIGHT']].std())\n",
    "print(testout.groupby([\"GENDER\"])[['WEIGHT','HEIGHT']].min())\n",
    "print(testout.groupby([\"GENDER\"])[['WEIGHT','HEIGHT']].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740f4ea",
   "metadata": {},
   "source": [
    "## The following are available in groupby\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/groupby.html\n",
    "\n",
    "    -gb.agg        gb.boxplot    gb.cummin     gb.describe   gb.filter     \n",
    "    -gb.get_group  gb.height     gb.last       gb.median     gb.ngroups    \n",
    "    -gb.plot       gb.rank       gb.std        gb.transform\n",
    "    -gb.aggregate  gb.count      gb.cumprod    gb.dtype      gb.first      \n",
    "    -gb.groups     gb.hist       gb.max        gb.min        gb.nth        \n",
    "    -gb.prod       gb.resample   gb.sum        gb.var\n",
    "    -gb.apply      gb.cummax     gb.cumsum     gb.fillna     gb.gender     \n",
    "    -gb.head       gb.indices    gb.mean       gb.name       gb.ohlc       \n",
    "    -gb.quantile   gb.size       gb.tail       gb.weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9de2d",
   "metadata": {},
   "source": [
    "### Generate frequency 2&2 frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7332ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the output changes as you use different parameters\n",
    "print(pd.crosstab(testout.GENDER, testout.STATURE, margins=False))\n",
    "print(pd.crosstab(testout.GENDER, testout.STATURE, margins=True))\n",
    "print(pd.crosstab(testout.GENDER, testout.STATURE, margins=True,normalize=True))\n",
    "print(pd.crosstab(testout.GENDER, testout.STATURE, margins=True,normalize='all')) #Sum of all will be 1\n",
    "print(pd.crosstab(testout.GENDER, testout.STATURE, margins=True,normalize='index')) #Sum of row values will be 1\n",
    "print(pd.crosstab(testout.GENDER, testout.STATURE, margins=True,normalize='columns')) #Sum of column values will be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6f950",
   "metadata": {},
   "source": [
    "## Plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize the data, you can use matplotlib\n",
    "# Please make sure you have matplotlib installed\n",
    "# If not, you can install it using the following command\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##plot histogram where you can specify the number of bins or the bin edges\n",
    "#plt.hist(testout['WEIGHT'],bins=5)\n",
    "plt.hist(testout['WEIGHT'],bins=[40,50,60,70,80,90,100])\n",
    "plt.title('Histogram with auto bins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73c3af",
   "metadata": {},
   "source": [
    "### Transpose the data\n",
    "\n",
    "Use **melt** to tranpose the data\n",
    "\n",
    "Date column will become the first column, column name will become 'id' and column values will be called 'return'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################Read the data and transpose for easier analysis################\n",
    "sample=pd.read_excel('./note1data.xlsx', sheet_name=\"SAMPLE\", header=0)\n",
    "print(sample) #print the sample dataframe\n",
    "print(sample.columns) # print the columns of the sample dataframe\n",
    "print(os.getcwd()) #print out the current working directory\n",
    "\n",
    "print(sample.iloc[0:4,0:3]) #print out first 4 rows and first 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13bac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pd.melt to transform the dataframe from wide format to long format\n",
    "sampletran=pd.melt(sample,id_vars=['Date'],var_name='id',value_name='return')\n",
    "print(sampletran.columns)# Check how the columns are transformed\n",
    "print(sampletran) #print the transformed dataframe\n",
    "print(sampletran.head(10)) #print out the first 10 rows\n",
    "print(sampletran.tail(8)) #print out the last 8 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307e7dd-ae0d-4921-aec4-dff6daddba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a new worksheet to an existing excel file\n",
    "# Create a Pandas Excel writer using Openpyxl as the engine.\n",
    "import openpyxl\n",
    "writer = pd.ExcelWriter('./note1_out.xlsx', engine='openpyxl', mode='a')\n",
    "\n",
    "# Get the list of existing worksheets\n",
    "print(writer.book.sheetnames)\n",
    "\n",
    "# Write the DataFrame to the new worksheet\n",
    "sampletran.to_excel(writer, sheet_name='sampletran', startrow=0, startcol=0, index=False)\n",
    "\n",
    "# Save the changes to the Excel file\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ad32f",
   "metadata": {},
   "source": [
    "# SQL\n",
    "\n",
    "Let's import RData (data saved in R) to import Rdata\n",
    "\n",
    "Install **pyreadr** using the following command if not installed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49aaee4c-8177-4f9d-8581-8f96a61c4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr #package used to read RData, data used in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1394a3-38ad-43f1-a943-11345b562dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pyreadr.read_r('.\\\\note1.RData') # Read the RData file\n",
    "# The result is a dictionary with the dataframes as values\n",
    "print(type(data1))\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80038322-0f76-4280-8303-5eecb3c78c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['mdata'])\n"
     ]
    }
   ],
   "source": [
    "# Check the keys of the dictionary to see the names of the dataframes\n",
    "print(data1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876db5b-4530-4b93-a426-3c0d96b29ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the specific dataframe from the dictionary\n",
    "# Here, 'mdata' is the name of the dataframe in the RData file\n",
    "data2=data1['mdata']#mdata is the table in RData\n",
    "print(type(data2)) #Check the type of the diciontary's values\n",
    "print(data2.head()) # #print the first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7b226-cd65-4033-a53e-173cf30b80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2.iloc[1:10,]) #check the first 10 rows of the dataframe\n",
    "print(data2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e54dac",
   "metadata": {},
   "source": [
    "### How to run SQL in Python\n",
    "\n",
    "There are different ways to run SQL.  We will use pandasql that is convenient to run sql using pandas dataframes\n",
    "\n",
    "Functions available in pandasql\n",
    "\n",
    "    -AVG() – returns the average value of a group.\n",
    "    -COUNT() – returns the number of rows that match a specified condition\n",
    "    -MAX() – returns the maximum value in a group.\n",
    "    -MIN() – returns the minimum value in a group\n",
    "    -SUM() – returns the sum of values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edffcaf",
   "metadata": {},
   "source": [
    "https://community.alteryx.com/t5/Data-Science-Blog/pandasql-Make-python-speak-SQL/ba-p/138435\n",
    "\n",
    "First install pandasql if not installed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2931d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa699aea-fa89-4572-ab69-15c49717ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the pandasql package, sqldf is a function that allows you to run SQL queries on pandas dataframes\n",
    "# You can import it as follows\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dd55d3a-3695-482c-8560-aa6220431813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a query statement to be used inside the sqldf function\n",
    "\n",
    "query1='''select a.id,avg(a.return) as mean, \n",
    "                 min(a.return) as minimum, max(a.return) as maximum, \n",
    "                 count(a.return) as number\n",
    "             from data2 as a \n",
    "             group by a.id\n",
    "             order by a.id'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2e9fa",
   "metadata": {},
   "source": [
    "#### locals() vs. globals()\n",
    "\n",
    "When you use sqldf(query statement, locals/globals), you have to specify\n",
    "whether the variables are used locally or globally by specifying either locals() or globals() inside sqldf()\n",
    "\n",
    "When pandasql needs to have access to other variables in your session/environment, you can pass locals() to pandasql when executing a SQL statement.\n",
    "\n",
    "But if you're running a lot of queries requiring locals(), it might be a pain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When locals() are specified, the variables are accessed from the local scope\n",
    "# When globals() are specified, the variables are accessed from the global scope\n",
    "df1=sqldf(query1,locals())\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5117d3",
   "metadata": {},
   "source": [
    "### Alternatively, you can define a function including globals()\n",
    "\n",
    "To avoid passing locals all the time, you can add this helper function to your script to set globals() like so:\n",
    "\n",
    "Define your custom function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d663f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can define a function including globals()\n",
    "# To avoid passing locals all the time, you can add this helper function to your script to\n",
    "def pysqldf(q):\n",
    " return sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510b04e",
   "metadata": {},
   "source": [
    "If you use locals() above instead of globals(), you will get error message since it does not recognize data2 that is defined outside function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use your defined function to run the SQL query that was defined earlier\n",
    "meansql=pysqldf(query1)\n",
    "print(df1) #Query output using sqldf(locals())\n",
    "print(meansql) #Query output using pysqldf(globals())\n",
    "# The output should be the same as df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d65fd5-dda1-4a01-9312-908107e94980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can defined a query statement inside the pysqldf function\n",
    "pysqldf('''select a.id,avg(a.return) as mean, \n",
    "                 min(a.return) as minimum, max(a.return) as maximum, \n",
    "                 count(a.return) as number\n",
    "             from data2 as a \n",
    "             group by a.id\n",
    "             order by a.id''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0131f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also store the output of the query directly into a dataframe.\n",
    "mdata1=pysqldf('''select a.id,a.date,a.return from data2 as a order by a.id,a.date''')\n",
    "print(data2.columns)\n",
    "print(mdata1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3420eba9",
   "metadata": {},
   "source": [
    "### Calculate group means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8406a16-73a0-48c3-8cd7-ef0f667fa293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate group means using groupby and agg functions\n",
    "# You can use the groupby function to group the data by 'id' and then calculate\n",
    "grouped=data2.groupby('id',observed=False)['return']#observed=False means that even the ones with ID caltegory missing will be included\n",
    "print(grouped.agg(['mean','min','max','std','count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b1494-5374-4402-a5f4-cf7ec3fe35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a more detailed description of the grouped data, you can use the describe() function\n",
    "# This will give you a summary of the statistics for each group\n",
    "print(data2.groupby('id',observed=False)['return'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20180e49-1cf0-427f-861a-a1dc7ad5fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, you can calculate the mean, min, max, std, and count for each group using the following commands\n",
    "\n",
    "print('mean:  ', data2.groupby('id',observed=False)['return'].mean())\n",
    "print('min:  ', data2.groupby('id',observed=False)['return'].min())\n",
    "print('max:  ', data2.groupby('id',observed=False)['return'].max())\n",
    "print('std:  ', data2.groupby('id',observed=False)['return'].std())\n",
    "print('count:  ', data2.groupby('id',observed=False)['return'].count())\n",
    "print('count-alt:  ', data2[(data2.id !=0)].groupby('id',observed=False)['return'].count()) #count only non-zeros\n",
    "\n",
    "###compare the results with the meansql\n",
    "print(meansql)\n",
    "#######################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
