{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099c7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np \n",
    "import vectorbt as vbt\n",
    "\n",
    "sp500 = pd.read_csv(\"./data/sp500_return.csv\", parse_dates=['date'], index_col=0)\n",
    "sp500_list = pd.read_csv(\"./data/sp500_list.csv\", index_col=0, parse_dates=['start','ending'])\n",
    "stock_id = pd.read_csv(\"./data/stock_id.csv\", index_col=0, parse_dates=['namedt','nameendt'])\n",
    "\n",
    "sp500.columns = sp500.columns.astype(int)\n",
    "sp500 = sp500.loc[\"1965-01-01\":\"2024-06-30\"]\n",
    "sp500_prices = (1+sp500).cumprod()\n",
    "\n",
    "orders = pd.DataFrame(index=sp500.index, columns=sp500.columns, dtype=float)\n",
    "orders_long = pd.DataFrame(index=sp500.index, columns=sp500.columns, dtype=float)\n",
    "orders_short = pd.DataFrame(index=sp500.index, columns=sp500.columns, dtype=float)\n",
    "comnam_map = stock_id[[\"namedt\", \"permno\", \"comnam\"]].drop_duplicates().groupby([\"permno\"])[\"comnam\"].last()\n",
    "\n",
    "short_list = pd.read_csv(\"./data/short_list.csv\", parse_dates=True, index_col=0)\n",
    "long_list = pd.read_csv(\"./data/long_list.csv\", parse_dates=True, index_col=0)\n",
    "\n",
    "# 오더를 만든다. 비율을 그냥 1/50, 똑같은 비중으로 2%씩 넣도록 했다. \n",
    "for i in range(len(long_list)):\n",
    "    start = long_list.index[i]\n",
    "    end = long_list.index[i] + relativedelta(months=1) - relativedelta(days=1)\n",
    "    start, end = sp500[start:end].index[0], sp500[start:end].index[-1]\n",
    "    long, short = long_list.iloc[i], short_list.iloc[i]\n",
    "    orders.loc[start] = 0\n",
    "    orders_long.loc[start] = 0\n",
    "    orders_short.loc[start] = 0\n",
    "    orders.loc[start, long] = 1 / 50\n",
    "    orders.loc[start, short] = -1 / 50\n",
    "    orders_long.loc[start, long] = 1/50\n",
    "    orders_short.loc[start, short] = 1 / 50\n",
    "\n",
    "# 상위 10%, 하위 10% 전략 수익률을 일단 따로따로 봤다. \n",
    "# 즉, 1) 전체, 2) 상위 10%, 3) 하위 10% 의 수익률을 따로따로 봤다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85716be",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"1965-01-01\"\n",
    "start_date = \"1990-01-01\" # 똑같은 성과를 90년도부터 본다면? 훨씬 성능 떨어지게 나온다. \n",
    "end_date = \"2025-12-31\"\n",
    "_prices = sp500_prices.loc[start_date:end_date]\n",
    "_orders = orders.loc[start_date:end_date]\n",
    "_orders_long = orders_long.loc[start_date:end_date]\n",
    "_orders_short = orders_short.loc[start_date:end_date]\n",
    "\n",
    "num_tests = 3\n",
    "_prices = _prices.vbt.tile(num_tests, keys=pd.Index([\"Long-Short\", \"Long\", \"Short\"], name='group'))\n",
    "_orders = pd.concat([_orders, _orders_long, _orders_short], axis=1)\n",
    "\n",
    "\n",
    "pf = vbt.Portfolio.from_orders(\n",
    "    close=_prices,\n",
    "    size=_orders,\n",
    "    size_type='target_percent',\n",
    "    fees=0.0, \n",
    "    freq='d',\n",
    "    init_cash=1000,\n",
    "    cash_sharing=True,\n",
    "    group_by='group')\n",
    "\n",
    "# 성과를 그려보면 역시 처음에는 잘되다가 나중에 안된다. \n",
    "# 교수님은 S&P500만 가지고 해서 논문에서 말한 뉴스 정보전달이 지연되서 나오는 효과 같은 것이 \n",
    "# 제대로 발휘되지 못했을 수 있다고 하심. (작은게 있어야 효과 최대)\n",
    "\n",
    "# 특이한 점: 롱숏 나눠서 찍어보면, 롱 성과가 완전 압도하는 것을 알 수 있다. \n",
    "\n",
    "#pf.orders.records_readable\n",
    "fig = pf.value().vbt.plot()\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        #type=\"log\", # 시작점에 의해 차이 매우 뻥튀기 되어 보이는 것 보완해야. \n",
    "                     # log scale로 바꾸면 \n",
    "        title=\"Portfolio Value (log scale)\",\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor='lightgray'\n",
    "    ),\n",
    "    title=\"Portfolio Value Over Time (Log Scale)\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# 교훈\n",
    "## 1. 복리로 투자한 결과는 볼 때 유의해야 한다. 시작점에 dependent 한 것은 book이 점점 올라가기 때문. \n",
    "### 따라서 매번 같은 금액 투자하는걸로 봐야 path dependent 하지 않게 pnl 비교 가능. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
